{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e865045",
   "metadata": {},
   "source": [
    "IA3配条代码参考自：\n",
    "\n",
    "[peft_ia3_mindnlp.ipynb](https://github.com/mindspore-lab/mindnlp/tree/master/llm/peft/ia3/seq_2_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1abbd02",
   "metadata": {},
   "source": [
    "模型配置参考：基于MindSpore NLP的Roberta模型Prompt Tuning\n",
    "\n",
    "https://blog.csdn.net/Kenji_Shinji/article/details/144395136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f93b7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.306 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mindspore\n",
    "from mindnlp.transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from mindnlp.peft import get_peft_config, get_peft_model, get_peft_model_state_dict, LoraConfig, TaskType,IA3Config\n",
    "from mindnlp.dataset import load_dataset\n",
    "from mindnlp.core import ops\n",
    "from mindnlp.common.optimization import get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "from mindnlp import evaluate\n",
    "\n",
    "model_name_or_path = \"roberta-large\"\n",
    "tokenizer_name_or_path = \"roberta-large\"\n",
    "peft_type = peft.PeftType.IA3\n",
    "\n",
    "# checkpoint_name = \"financial_sentiment_analysis_lora_v1.ckpt\"\n",
    "checkpoint_name = \"RoBERTa_IA3_v1.ckpt\"\n",
    "max_length = 128\n",
    "lr = 1e-3\n",
    "num_epochs = 20\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d0850ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MS_ALLOC_CONF]Runtime config:  enable_vmm:True  vmm_align_size:2MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,223,682 || all params: 356,585,476 || trainable%: 0.34316652874555104\n"
     ]
    }
   ],
   "source": [
    "# creating model\n",
    "peft_config = peft.IA3Config(task_type=\"SEQ_CLS\", inference_mode=False) #TaskType从SEQ_2_SEQ_LM修改为SEQ_CLS\n",
    "#TaskType.SEQ_2_SEQ_LM 是专门为序列到序列生成任务（如机器翻译、文本摘要等）设计的。对于 RoBERTa 模型和 AutoModelForSequenceClassification，你应该将 task_type 设置为 TaskType.SEQ_CLS，因为这是针对序列分类任务的正确配置。\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path) #对应修改为AutoModelForSequenceClassification\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f9579f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindnlp/transformers/tokenization_utils_base.py:1526: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted, and will be then set to `False` by default. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#加载tokenizer\n",
    "if any(k in model_name_or_path for k in (\"gpt\", \"opt\", \"bloom\")):\n",
    "    padding_side = \"left\"\n",
    "else:\n",
    "    padding_side = \"right\"\n",
    " \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, padding_side=padding_side)\n",
    "if getattr(tokenizer, \"pad_token_id\") is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee2babf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence1': Tensor(shape=[], dtype=String, value= 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .'), 'sentence2': Tensor(shape=[], dtype=String, value= 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'), 'label': Tensor(shape=[], dtype=Int64, value= 1), 'idx': Tensor(shape=[], dtype=Int64, value= 0)}\n"
     ]
    }
   ],
   "source": [
    "# mindspore.dataset.config.set_seed(123)\n",
    "# loading dataset\n",
    "# dataset = load_dataset(\"financial_phrasebank\", \"sentences_allagree\")\n",
    "datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "print(next(datasets['train'].create_dict_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f226e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindnlp.dataset import BaseMapFunction\n",
    " \n",
    "class MapFunc(BaseMapFunction):\n",
    "    def __call__(self, sentence1, sentence2, label, idx):\n",
    "        outputs = tokenizer(sentence1, sentence2, truncation=True, max_length=None)\n",
    "        return outputs['input_ids'], outputs['attention_mask'], label\n",
    " \n",
    "def get_dataset(dataset, tokenizer):\n",
    "    input_colums=['sentence1', 'sentence2', 'label', 'idx']\n",
    "    output_columns=['input_ids', 'attention_mask', 'labels']\n",
    "    dataset = dataset.map(MapFunc(input_colums, output_columns),\n",
    "                          input_colums, output_columns)\n",
    "    dataset = dataset.padded_batch(batch_size, pad_info={'input_ids': (None, tokenizer.pad_token_id),\n",
    "                                                         'attention_mask': (None, 0)})\n",
    "    return dataset\n",
    " \n",
    "train_dataset = get_dataset(datasets['train'], tokenizer)\n",
    "eval_dataset = get_dataset(datasets['validation'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13ea3fc6-f1aa-486f-a81a-9f41cc7ef5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': Tensor(shape=[32, 70], dtype=Int64, value=\n",
      "[[    0, 10127,  1001 ...     1,     1,     1],\n",
      " [    0,   975, 26802 ...     1,     1,     1],\n",
      " [    0,  1213,    56 ...     1,     1,     1],\n",
      " ...\n",
      " [    0,   133,  1154 ...     1,     1,     1],\n",
      " [    0, 12667,  8423 ...     1,     1,     1],\n",
      " [    0, 32478,  1033 ...     1,     1,     1]]), 'attention_mask': Tensor(shape=[32, 70], dtype=Int64, value=\n",
      "[[1, 1, 1 ... 0, 0, 0],\n",
      " [1, 1, 1 ... 0, 0, 0],\n",
      " [1, 1, 1 ... 0, 0, 0],\n",
      " ...\n",
      " [1, 1, 1 ... 0, 0, 0],\n",
      " [1, 1, 1 ... 0, 0, 0],\n",
      " [1, 1, 1 ... 0, 0, 0]]), 'labels': Tensor(shape=[32], dtype=Int64, value= [1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, \n",
      " 1, 1, 0, 0, 1, 1, 1, 0])}\n"
     ]
    }
   ],
   "source": [
    "print(next(train_dataset.create_dict_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e052eea-f6d6-4a22-a71a-bef47abafffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"glue\", \"mrpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ceb546f-8bf9-4ded-ab8d-cab5048594ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,223,682 || all params: 356,585,476 || trainable%: 0.34316652874555104\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, return_dict=True)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f733a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindnlp.core import optim\n",
    "# optimizer and lr scheduler\n",
    "optimizer = optim.AdamW(model.trainable_params(), lr=lr)\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=(len(train_dataset) * num_epochs),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5e65888-89b1-4f12-ad54-c2eeeed6756d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/115 [00:02<05:17,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:47<00:00,  2.44it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0: train_ppl=Tensor(shape=[], dtype=Float32, value= 1.95144) train_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.668568) eval_ppl=Tensor(shape=[], dtype=Float32, value= 1.8664) eval_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.62401)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:43<00:00,  2.66it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1: train_ppl=Tensor(shape=[], dtype=Float32, value= 1.91617) train_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.650329) eval_ppl=Tensor(shape=[], dtype=Float32, value= 1.88799) eval_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.635512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:41<00:00,  2.76it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=2: train_ppl=Tensor(shape=[], dtype=Float32, value= 1.92575) train_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.655313) eval_ppl=Tensor(shape=[], dtype=Float32, value= 1.88011) eval_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.631329)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:38<00:00,  3.01it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=3: train_ppl=Tensor(shape=[], dtype=Float32, value= 1.91941) train_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.652019) eval_ppl=Tensor(shape=[], dtype=Float32, value= 1.87401) eval_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.628081)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:42<00:00,  2.69it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=4: train_ppl=Tensor(shape=[], dtype=Float32, value= 1.91305) train_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.6487) eval_ppl=Tensor(shape=[], dtype=Float32, value= 1.8705) eval_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.626204)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:40<00:00,  2.82it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=5: train_ppl=Tensor(shape=[], dtype=Float32, value= 1.9048) train_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.644376) eval_ppl=Tensor(shape=[], dtype=Float32, value= 1.86736) eval_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.624525)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:37<00:00,  3.03it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=6: train_ppl=Tensor(shape=[], dtype=Float32, value= 1.90935) train_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.646765) eval_ppl=Tensor(shape=[], dtype=Float32, value= 1.86331) eval_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.622357)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:42<00:00,  2.71it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=7: train_ppl=Tensor(shape=[], dtype=Float32, value= 1.912) train_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.648148) eval_ppl=Tensor(shape=[], dtype=Float32, value= 1.86376) eval_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.622594)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:43<00:00,  2.67it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=8: train_ppl=Tensor(shape=[], dtype=Float32, value= 1.90793) train_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.646019) eval_ppl=Tensor(shape=[], dtype=Float32, value= 1.86808) eval_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.624912)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:40<00:00,  2.81it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=9: train_ppl=Tensor(shape=[], dtype=Float32, value= 1.90432) train_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.644126) eval_ppl=Tensor(shape=[], dtype=Float32, value= 1.88019) eval_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.631374)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:39<00:00,  2.93it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=10: train_ppl=Tensor(shape=[], dtype=Float32, value= 1.89971) train_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.6417) eval_ppl=Tensor(shape=[], dtype=Float32, value= 1.88421) eval_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.633507)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:45<00:00,  2.55it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=11: train_ppl=Tensor(shape=[], dtype=Float32, value= 1.90593) train_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.644971) eval_ppl=Tensor(shape=[], dtype=Float32, value= 1.87726) eval_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.629814)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:44<00:00,  2.61it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=12: train_ppl=Tensor(shape=[], dtype=Float32, value= 1.89415) train_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.63877) eval_ppl=Tensor(shape=[], dtype=Float32, value= 1.86392) eval_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.622681)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:40<00:00,  2.85it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=13: train_ppl=Tensor(shape=[], dtype=Float32, value= 1.89836) train_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.640992) eval_ppl=Tensor(shape=[], dtype=Float32, value= 1.86388) eval_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.62266)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:40<00:00,  2.82it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=14: train_ppl=Tensor(shape=[], dtype=Float32, value= 1.89915) train_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.641409) eval_ppl=Tensor(shape=[], dtype=Float32, value= 1.86373) eval_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.622579)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:40<00:00,  2.85it/s]\n",
      "100%|██████████| 13/13 [00:02<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=15: train_ppl=Tensor(shape=[], dtype=Float32, value= 1.89471) train_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.639068) eval_ppl=Tensor(shape=[], dtype=Float32, value= 1.8634) eval_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.622404)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:44<00:00,  2.60it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=16: train_ppl=Tensor(shape=[], dtype=Float32, value= 1.89206) train_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.637667) eval_ppl=Tensor(shape=[], dtype=Float32, value= 1.8651) eval_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.623315)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:39<00:00,  2.90it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=17: train_ppl=Tensor(shape=[], dtype=Float32, value= 1.89262) train_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.637962) eval_ppl=Tensor(shape=[], dtype=Float32, value= 1.86385) eval_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.622643)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:39<00:00,  2.92it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=18: train_ppl=Tensor(shape=[], dtype=Float32, value= 1.8854) train_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.63414) eval_ppl=Tensor(shape=[], dtype=Float32, value= 1.8643) eval_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.622884)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:45<00:00,  2.50it/s]\n",
      "100%|██████████| 13/13 [00:02<00:00,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=19: train_ppl=Tensor(shape=[], dtype=Float32, value= 1.88236) train_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.632527) eval_ppl=Tensor(shape=[], dtype=Float32, value= 1.86346) eval_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.622437)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from mindnlp.core import value_and_grad\n",
    "# training and evaluation\n",
    "\n",
    "def forward_fn(**batch):\n",
    "    outputs = model(**batch)\n",
    "    loss = outputs.loss\n",
    "    return loss\n",
    "\n",
    "# 使用value_and_grad装饰前向传播函数，以便在训练时获取损失值和梯度\n",
    "grad_fn = value_and_grad(forward_fn, model.trainable_params())\n",
    "\n",
    "# 开始训练和评估循环\n",
    "for epoch in range(num_epochs):\n",
    "    # 设置模型为训练模式\n",
    "    model.set_train()\n",
    "    total_loss = 0\n",
    "    train_total_size = train_dataset.get_dataset_size()\n",
    "    # 遍历训练数据集\n",
    "    for step, batch in enumerate(tqdm(train_dataset.create_dict_iterator(), total=train_total_size)):\n",
    "        # 清除上一步的梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 计算损失值和梯度\n",
    "        loss = grad_fn(**batch)\n",
    "         # 更新模型参数\n",
    "        optimizer.step()\n",
    "        # 累加损失值\n",
    "        total_loss += loss.float() #这一步不一样\n",
    "        # 更新学习率调度器\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    # 设置模型为评估模式\n",
    "    model.set_train(False)\n",
    "    eval_loss = 0 #这一步没有\n",
    "    eval_preds = [] #这一步没有\n",
    "    eval_total_size = eval_dataset.get_dataset_size()\n",
    "    # 遍历评估数据集\n",
    "    for step, batch in enumerate(tqdm(eval_dataset.create_dict_iterator(), total=eval_total_size)):\n",
    "        # 禁用梯度计算，进行前向传播\n",
    "        with mindspore._no_grad(): # 没有这句\n",
    "            outputs = model(**batch)\n",
    "        loss = outputs.loss        # 以下都不一样\n",
    "        eval_loss += loss.float()\n",
    "         # 将模型预测结果解码为文本并存储\n",
    "        #eval_preds.extend(\n",
    "        #    tokenizer.batch_decode(ops.argmax(outputs.logits, -1).asnumpy(), skip_special_tokens=True)\n",
    "        #)\n",
    "\n",
    "        # 对于序列分类任务，直接获取类别索引\n",
    "        eval_preds.extend(ops.argmax(outputs.logits, -1).asnumpy().tolist())\n",
    "    \n",
    "# 计算评估期损失\n",
    "    eval_epoch_loss = eval_loss / len(eval_dataset)\n",
    "    eval_ppl = ops.exp(eval_epoch_loss)\n",
    "# 计算训练期损失\n",
    "    train_epoch_loss = total_loss / len(train_dataset)\n",
    "    train_ppl = ops.exp(train_epoch_loss)\n",
    "# 打印训练和评估结果\n",
    "    print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=} {eval_ppl=} {eval_epoch_loss=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b95a29e-3b1c-493e-916d-cb7bd5c1f44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_preds=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(f\"{eval_preds=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a913d1b6-f30d-496d-a970-ea097ecd210c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample logits: [[-0.64343876  0.10822424]\n",
      " [-0.64343876  0.10822424]\n",
      " [-0.64343876  0.10822424]\n",
      " [-0.64343876  0.10822424]\n",
      " [-0.64343876  0.10822424]\n",
      " [-0.64343876  0.10822424]\n",
      " [-0.6434387   0.10822434]\n",
      " [-0.6434387   0.10822434]\n",
      " [-0.6434387   0.10822434]\n",
      " [-0.6434387   0.10822434]\n",
      " [-0.6434387   0.10822434]\n",
      " [-0.6434386   0.10822422]\n",
      " [-0.6434386   0.10822422]\n",
      " [-0.6434386   0.10822422]\n",
      " [-0.6434386   0.10822422]\n",
      " [-0.6434386   0.10822422]\n",
      " [-0.64343876  0.10822424]\n",
      " [-0.64343876  0.10822424]\n",
      " [-0.64343876  0.10822424]\n",
      " [-0.64343876  0.10822424]\n",
      " [-0.64343876  0.10822424]\n",
      " [-0.64343876  0.10822424]\n",
      " [-0.64343876  0.10822424]\n",
      " [-0.64343876  0.10822424]]\n"
     ]
    }
   ],
   "source": [
    "# 打印前5个样本的logits\n",
    "print(f\"Sample logits: {outputs.logits[:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b6c252c-f6d1-41f0-935b-e7b2aed0863f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m ground_truth\u001b[38;5;241m.\u001b[39mappend(true)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 如果预测的标签与真实标签一致，则正确计数器加一\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m() \u001b[38;5;241m==\u001b[39m true\u001b[38;5;241m.\u001b[39mstrip():\n\u001b[1;32m     17\u001b[0m     correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 总样本计数器加一\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "# print accuracy\n",
    "# 初始化正确预测和总样本的计数器\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# 初始化用于存储真实标签的列表\n",
    "ground_truth = []\n",
    "\n",
    "# 遍历预测结果和验证数据集\n",
    "for pred, data in zip(eval_preds, datasets['validation'].create_dict_iterator(output_numpy=True)):\n",
    "    # 获取真实的文本标签\n",
    "    true = str(data['label'])\n",
    "    # 将真实标签添加到ground_truth列表中\n",
    "    ground_truth.append(true)\n",
    "    # 如果预测的标签与真实标签一致，则正确计数器加一\n",
    "    if pred.strip() == true.strip():\n",
    "        correct += 1\n",
    "    # 总样本计数器加一\n",
    "    total += 1\n",
    "# 计算准确率\n",
    "accuracy = correct / total * 100\n",
    "# 输出准确率\n",
    "print(f\"{accuracy=} % on the evaluation dataset\")\n",
    "# 输出前10个预测结果\n",
    "print(f\"{eval_preds[:10]=}\")\n",
    "# 输出前10个真实标签\n",
    "print(f\"{ground_truth[:10]=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77adfbb0-f8fc-43e0-aad2-42d7f604cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e88eb1-3d24-488b-ad62-0c18b81b861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取数据集迭代器的下一个元素\n",
    "next(eval_dataset.create_tuple_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8de6005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "# 构建PEFT模型的唯一标识符\n",
    "# 该标识符结合了模型名称或路径、PEFT配置的类型和任务类型，用于区分不同的PEFT模型\n",
    "peft_model_id = f\"{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}\"\n",
    "\n",
    "# 保存预训练的PEFT模型\n",
    "# 使用构建的PEFT模型标识符作为模型ID，将模型保存到指定目录或路径\n",
    "model.save_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd20cd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建checkpoint文件的路径\n",
    "ckpt = f\"{peft_model_id}/adapter_model.ckpt\"\n",
    "# 使用shell命令检查checkpoint文件的大小\n",
    "!du -h $ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c2fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入Peft模型和配置相关的模块\n",
    "from mindnlp.peft import PeftModel, PeftConfig\n",
    "\n",
    "# 构造Peft模型的唯一标识符\n",
    "# 这里使用模型名称或路径、Peft配置的类型和任务类型来组合成一个字符串\n",
    "peft_model_id = f\"{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}\"\n",
    "\n",
    "# 从预训练的Peft模型中加载配置\n",
    "# 这里的配置将指导如何加载和使用Peft模型\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "# 从配置中加载基础模型\n",
    "# 这个基础模型是用于执行序列到序列语言模型任务的\n",
    "model = AutoModelForSequenceClassification.from_pretrained(config.base_model_name_or_path)\n",
    "# 使用Peft模型对基础模型进行微调\n",
    "# 这一步是将基础模型与Peft模型的特定微调参数结合起来\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d712ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置模型为评估模式，以禁用dropout等训练时的行为\n",
    "model.set_train(False)\n",
    "# 从验证数据集中获取一个样本，以便后续进行推理演示\n",
    "example = next(validation_dataset.create_dict_iterator(output_numpy=True))\n",
    "\n",
    "# 打印样本中的文本标签，以便用户了解正在处理的数据\n",
    "print(example['idx'])\n",
    "# 使用tokenizer对样本文本进行编码，以将其转换为模型可处理的输入格式\n",
    "inputs = tokenizer(example['idx'], return_tensors=\"ms\")\n",
    "# 打印编码后的输入，以展示输入格式和内容\n",
    "print(inputs)\n",
    "\n",
    "# 禁用梯度计算，以减少计算资源消耗，因为推理过程不需要反向传播\n",
    "with mindspore._no_grad():\n",
    "    # 使用模型生成文本，指定最大新生成的令牌数量以限制输出长度\n",
    "    outputs = model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=10)\n",
    "    # 打印生成的文本编码，以展示模型的输出内容\n",
    "    print(outputs)\n",
    "    # 将生成的文本编码转换回人类可读的文本格式，并打印\n",
    "    print(tokenizer.batch_decode(outputs.asnumpy(), skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
