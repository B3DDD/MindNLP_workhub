{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于MindSpore NLP的Roberta模型Prompt Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原文链接：https://www.hiascend.com/forum/thread-02107166711681514014-1-1.html\n",
    "本文档介绍了如何基于MindSpore NLP进行Roberta模型的Prompt Tuning，主要用于GLUE基准数据集的微调。本文提供了完整的代码示例以及详细的步骤说明，便于理解和复现实验。\n",
    "\n",
    "配置环境\n",
    "\n",
    "在运行此代码前，请确保MindSpore NLP库已经安装。本文档基于大模型平台运行，因此需要进行适当的环境配置，确保代码可以在相应的平台上运行。\n",
    "\n",
    "模型与数据集加载\n",
    "\n",
    "在本案例中，我们使用 roberta-large 模型并基于GLUE基准数据集进行Prompt Tuning。GLUE (General Language Understanding Evaluation) 是自然语言处理中的标准评估基准，包括多个子任务，如句子相似性匹配、自然语言推理等。Prompt Tuning是一种新的微调技术，通过插入虚拟的“提示”Token在模型的输入中，以微调较少的参数达到较好的性能。\n",
    "————————————————\n",
    "\n",
    "                            版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。\n",
    "                        \n",
    "原文链接：https://blog.csdn.net/Kenji_Shinji/article/details/144395136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore\n",
    "from tqdm import tqdm\n",
    "from mindnlp import evaluate\n",
    "from mindnlp.dataset import load_dataset\n",
    "from mindnlp.transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from mindnlp.core.optim import AdamW\n",
    "from mindnlp.transformers.optimization import get_linear_schedule_with_warmup\n",
    "from mindnlp.peft import (\n",
    "    get_peft_model,\n",
    "    PeftType,\n",
    "    PromptTuningConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01\n",
    "\n",
    "定义训练参数 \n",
    "\n",
    "首先，定义模型名称、数据集任务名称、Prompt Tuning类型、训练轮数等基本参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "model_name_or_path = \"roberta-large\"\n",
    "task = \"mrpc\"\n",
    "peft_type = PeftType.PROMPT_TUNING\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02\n",
    "\n",
    "配置Prompt Tuning\n",
    "\n",
    "在Prompt Tuning的配置中，选择任务类型为\"SEQ_CLS\"（序列分类任务），并定义虚拟Token的数量。虚拟Token即为插入模型输入中的“提示”Token，通过这些Token的微调，使得模型能够更好地完成下游任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = PromptTuningConfig(task_type=\"SEQ_CLS\", num_virtual_tokens=10)\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "03\n",
    "\n",
    "加载Tokenizer \n",
    "\n",
    "根据模型类型选择padding的侧边，如果模型为GPT、OPT或BLOOM类模型，则从序列左侧填充（padding），否则从序列右侧填充。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if any(k in model_name_or_path for k in (\"gpt\", \"opt\", \"bloom\")):\n",
    "    padding_side = \"left\"\n",
    "else:\n",
    "    padding_side = \"right\"\n",
    " \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, padding_side=padding_side)\n",
    "if getattr(tokenizer, \"pad_token_id\") is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "04\n",
    "\n",
    "加载数据集 \n",
    "\n",
    "通过MindSpore NLP加载GLUE数据集，并打印样本以便确认数据格式。在此示例中，我们使用GLUE的MRPC（Microsoft Research Paraphrase Corpus）任务，该任务用于句子匹配，即判断两个句子是否表达相同的意思。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_dataset(\"glue\", task)\n",
    "print(next(datasets['train'].create_dict_iterator()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "05\n",
    "\n",
    "数据预处理  \n",
    "\n",
    "为了适配MindSpore NLP的数据处理流程，我们定义了一个映射函数 MapFunc，用于将句子转换为 input_ids 和 attention_mask，并对数据进行padding处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindnlp.dataset import BaseMapFunction\n",
    " \n",
    "class MapFunc(BaseMapFunction):\n",
    "    def __call__(self, sentence1, sentence2, label, idx):\n",
    "        outputs = tokenizer(sentence1, sentence2, truncation=True, max_length=None)\n",
    "        return outputs['input_ids'], outputs['attention_mask'], label\n",
    " \n",
    "def get_dataset(dataset, tokenizer):\n",
    "    input_colums=['sentence1', 'sentence2', 'label', 'idx']\n",
    "    output_columns=['input_ids', 'attention_mask', 'labels']\n",
    "    dataset = dataset.map(MapFunc(input_colums, output_columns),\n",
    "                          input_colums, output_columns)\n",
    "    dataset = dataset.padded_batch(batch_size, pad_info={'input_ids': (None, tokenizer.pad_token_id),\n",
    "                                                         'attention_mask': (None, 0)})\n",
    "    return dataset\n",
    " \n",
    "train_dataset = get_dataset(datasets['train'], tokenizer)\n",
    "eval_dataset = get_dataset(datasets['validation'], tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "06\n",
    "\n",
    "设置评估指标 \n",
    "\n",
    "我们使用 evaluate 模块加载评估指标（accuracy 和 F1-score）来评估模型的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"./glue.py\", task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "07\n",
    "\n",
    "加载模型并配置Prompt Tuning \n",
    "\n",
    "加载 roberta-large 模型，并根据配置进行Prompt Tuning。可以看到，微调的参数量仅为总参数量的0.3%左右，节省了大量计算资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, return_dict=True)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型微调（Prompt Tuning）\n",
    "\n",
    "在Prompt Tuning中，训练过程中仅微调部分参数（主要是虚拟Token相关的参数），相比于传统微调而言，大大减少了需要调整的参数量，使得模型能够高效适应下游任务。\n",
    "\n",
    "01\n",
    "\n",
    "优化器与学习率调整 \n",
    "\n",
    "使用 AdamW 优化器，并设置线性学习率调整策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(params=model.parameters(), lr=lr)\n",
    " \n",
    "# Instantiate scheduler\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0.06 * (len(train_dataset) * num_epochs),\n",
    "    num_training_steps=(len(train_dataset) * num_epochs),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02\n",
    "\n",
    "训练数据集 \n",
    "\n",
    "训练步骤如下：\n",
    "\n",
    "1、构建正向计算函数 forward_fn。\n",
    "\n",
    "2、定义梯度计算函数 grad_fn。\n",
    "\n",
    "3、定义每一步的训练逻辑 train_step。\n",
    "\n",
    "4、遍历数据集进行训练和评估，在每个 epoch 结束时，计算评估指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_fn(**batch):\n",
    "    outputs = model(**batch)\n",
    "    loss = outputs.loss\n",
    "    return loss\n",
    " \n",
    "grad_fn = mindspore.value_and_grad(forward_fn, None, tuple(model.parameters()))\n",
    " \n",
    "def train_step(**batch):\n",
    "    loss, grads = grad_fn(**batch)\n",
    "    optimizer.step(grads)\n",
    "    return loss\n",
    " \n",
    "for epoch in range(num_epochs):\n",
    "    model.set_train()\n",
    "    train_total_size = train_dataset.get_dataset_size()\n",
    "    for step, batch in enumerate(tqdm(train_dataset.create_dict_iterator(), total=train_total_size)):\n",
    "        loss = train_step(**batch)\n",
    "        lr_scheduler.step()\n",
    " \n",
    "    model.set_train(False)\n",
    "    eval_total_size = eval_dataset.get_dataset_size()\n",
    "    for step, batch in enumerate(tqdm(eval_dataset.create_dict_iterator(), total=eval_total_size)):\n",
    "        outputs = model(**batch)\n",
    "        predictions = outputs.logits.argmax(axis=-1)\n",
    "        predictions, references = predictions, batch[\"labels\"]\n",
    "        metric.add_batch(\n",
    "            predictions=predictions,\n",
    "            references=references,\n",
    "        )\n",
    " \n",
    "    eval_metric = metric.compute()\n",
    "    print(f\"epoch {epoch}:\", eval_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结\n",
    "\n",
    "本案例通过Prompt Tuning技术，在Roberta模型上进行了微调以适应GLUE数据集任务。通过控制微调参数量，Prompt Tuning展示了较强的高效性。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
