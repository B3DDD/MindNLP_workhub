{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e865045",
   "metadata": {},
   "source": [
    "IA3配条代码参考自：\n",
    "\n",
    "[peft_ia3_mindnlp.ipynb](https://github.com/mindspore-lab/mindnlp/tree/master/llm/peft/ia3/seq_2_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1abbd02",
   "metadata": {},
   "source": [
    "模型配置参考：基于MindSpore NLP的Roberta模型Prompt Tuning\n",
    "\n",
    "https://blog.csdn.net/Kenji_Shinji/article/details/144395136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f93b7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.308 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mindspore\n",
    "from mindnlp.transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from mindnlp.peft import get_peft_config, get_peft_model, get_peft_model_state_dict, LoraConfig, TaskType,IA3Config\n",
    "from mindnlp.dataset import load_dataset\n",
    "from mindnlp.core import ops\n",
    "from mindnlp.common.optimization import get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "from mindnlp import evaluate\n",
    "\n",
    "model_name_or_path = \"roberta-large\"\n",
    "tokenizer_name_or_path = \"roberta-large\"\n",
    "\n",
    "# checkpoint_name = \"financial_sentiment_analysis_lora_v1.ckpt\"\n",
    "checkpoint_name = \"RoBERTa_IA3_v1.ckpt\"\n",
    "\n",
    "# 优化训练表现可以调整以下数值\n",
    "max_length = 128\n",
    "lr = 1e-4\n",
    "num_epochs = 1\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d0850ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MS_ALLOC_CONF]Runtime config:  enable_vmm:True  vmm_align_size:2MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,223,682 || all params: 356,585,476 || trainable%: 0.34316652874555104\n"
     ]
    }
   ],
   "source": [
    "# creating model\n",
    "peft_config = IA3Config(task_type=TaskType.SEQ_CLS, inference_mode=False) #TaskType从SEQ_2_SEQ_LM修改为SEQ_CLS\n",
    "#TaskType.SEQ_2_SEQ_LM 是专门为序列到序列生成任务（如机器翻译、文本摘要等）设计的。对于 RoBERTa 模型和 AutoModelForSequenceClassification，你应该将 task_type 设置为 TaskType.SEQ_CLS，因为这是针对序列分类任务的正确配置。\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, return_dict=True) #对应修改为AutoModelForSequenceClassification\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f9579f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindnlp/transformers/tokenization_utils_base.py:1526: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted, and will be then set to `False` by default. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#加载tokenizer\n",
    "if any(k in model_name_or_path for k in (\"gpt\", \"opt\", \"bloom\")):\n",
    "    padding_side = \"left\"\n",
    "else:\n",
    "    padding_side = \"right\"\n",
    " \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, padding_side=padding_side)\n",
    "if getattr(tokenizer, \"pad_token_id\") is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee2babf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence1': Tensor(shape=[], dtype=String, value= 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .'), 'sentence2': Tensor(shape=[], dtype=String, value= 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'), 'label': Tensor(shape=[], dtype=Int64, value= 1), 'idx': Tensor(shape=[], dtype=Int64, value= 0)}\n"
     ]
    }
   ],
   "source": [
    "# mindspore.dataset.config.set_seed(123)\n",
    "# loading dataset\n",
    "# dataset = load_dataset(\"financial_phrasebank\", \"sentences_allagree\")\n",
    "datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "print(next(datasets['train'].create_dict_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f226e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindnlp.dataset import BaseMapFunction\n",
    " \n",
    "class MapFunc(BaseMapFunction):\n",
    "    def __call__(self, sentence1, sentence2, label, idx):\n",
    "        outputs = tokenizer(sentence1, sentence2, truncation=True, max_length=None)\n",
    "        return outputs['input_ids'], outputs['attention_mask'], label\n",
    " \n",
    "def get_dataset(dataset, tokenizer):\n",
    "    input_colums=['sentence1', 'sentence2', 'label', 'idx']\n",
    "    output_columns=['input_ids', 'attention_mask', 'labels']\n",
    "    dataset = dataset.map(MapFunc(input_colums, output_columns),\n",
    "                          input_colums, output_columns)\n",
    "    dataset = dataset.padded_batch(batch_size, pad_info={'input_ids': (None, tokenizer.pad_token_id),\n",
    "                                                         'attention_mask': (None, 0)})\n",
    "    return dataset\n",
    " \n",
    "train_dataset = get_dataset(datasets['train'], tokenizer)\n",
    "eval_dataset = get_dataset(datasets['validation'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13ea3fc6-f1aa-486f-a81a-9f41cc7ef5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': Tensor(shape=[8, 67], dtype=Int64, value=\n",
      "[[    0, 10127,  1001 ...     1,     1,     1],\n",
      " [    0,   975, 26802 ...     1,     1,     1],\n",
      " [    0,  1213,    56 ...     1,     1,     1],\n",
      " ...\n",
      " [    0,  9064, 32497 ...     1,     1,     1],\n",
      " [    0,   133,  4417 ...     1,     1,     1],\n",
      " [    0,   133, 19888 ...     1,     1,     1]]), 'attention_mask': Tensor(shape=[8, 67], dtype=Int64, value=\n",
      "[[1, 1, 1 ... 0, 0, 0],\n",
      " [1, 1, 1 ... 0, 0, 0],\n",
      " [1, 1, 1 ... 0, 0, 0],\n",
      " ...\n",
      " [1, 1, 1 ... 0, 0, 0],\n",
      " [1, 1, 1 ... 0, 0, 0],\n",
      " [1, 1, 1 ... 0, 0, 0]]), 'labels': Tensor(shape=[8], dtype=Int64, value= [1, 0, 1, 0, 1, 1, 0, 1])}\n"
     ]
    }
   ],
   "source": [
    "print(next(train_dataset.create_dict_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e052eea-f6d6-4a22-a71a-bef47abafffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"glue\", \"mrpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e01b3c38-3d33-4953-8a8b-9c89465a68da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindnlp.core import optim\n",
    "# optimizer and lr scheduler\n",
    "optimizer = optim.AdamW(model.trainable_params(), lr=lr)\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0.06 * (len(train_dataset) * num_epochs),\n",
    "    num_training_steps=(len(train_dataset) * num_epochs),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "500a27b5-045a-4e49-8149-6b287c6b958a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 459/459 [03:00<00:00,  2.55it/s]\n",
      "  2%|▏         | 1/51 [00:00<00:17,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.728428), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.48040873e-01,  4.22773451e-01],\n",
      " [-4.45561886e-01,  3.94312233e-01],\n",
      " [-2.11284250e-01,  7.98318684e-02],\n",
      " ...\n",
      " [-4.48380202e-01,  4.06560034e-01],\n",
      " [-4.30845946e-01,  3.97852480e-01],\n",
      " [-4.78388518e-01,  3.75581652e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/51 [00:00<00:14,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.541961), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-3.42127383e-01,  2.15243861e-01],\n",
      " [-4.41872180e-01,  4.12963808e-01],\n",
      " [-3.49417776e-01,  1.84000209e-01],\n",
      " ...\n",
      " [-4.23603266e-01,  2.92671263e-01],\n",
      " [-4.19992357e-01,  4.01182175e-01],\n",
      " [-4.61189926e-01,  4.09017563e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/51 [00:00<00:13,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.698053), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.34199810e-01,  4.05034721e-01],\n",
      " [-1.77049965e-01,  7.60205612e-02],\n",
      " [-4.27384883e-01,  4.05887485e-01],\n",
      " ...\n",
      " [-3.63760591e-01,  1.57332569e-01],\n",
      " [-4.33811486e-01,  4.04323637e-01],\n",
      " [-4.87705976e-01,  4.34066415e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 5/51 [00:01<00:08,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.591337), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-3.86733532e-01,  2.19754234e-01],\n",
      " [-4.20413345e-01,  3.97929072e-01],\n",
      " [-4.08392549e-01,  3.71933043e-01],\n",
      " ...\n",
      " [-3.41886252e-01,  1.77433074e-01],\n",
      " [-4.21778828e-01,  3.84547323e-01],\n",
      " [-4.08132225e-01,  2.75232613e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.658086), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.61596519e-01,  4.37176466e-01],\n",
      " [-3.80917013e-01,  3.45444709e-01],\n",
      " [-4.34063077e-01,  3.96820962e-01],\n",
      " ...\n",
      " [-3.25393200e-01,  2.00236619e-01],\n",
      " [-4.11928743e-01,  3.74880373e-01],\n",
      " [-5.34627974e-01,  3.78186315e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.844397), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.50617254e-01,  4.16772157e-01],\n",
      " [-3.98334742e-01,  3.61992627e-01],\n",
      " [-4.47454512e-01,  4.12347019e-01],\n",
      " ...\n",
      " [-4.84218270e-01,  3.36542547e-01],\n",
      " [-3.47260833e-01,  2.06144646e-01],\n",
      " [-4.02494222e-01,  3.72055709e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 7/51 [00:01<00:06,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.35823), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.28457886e-01,  3.85606498e-01],\n",
      " [-5.17000079e-01,  4.75543022e-01],\n",
      " [-4.59046483e-01,  4.26012993e-01],\n",
      " ...\n",
      " [-4.11107183e-01,  3.84928703e-01],\n",
      " [-4.36031789e-01,  3.95898283e-01],\n",
      " [-4.54775274e-01,  4.13025022e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.490555), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-3.73418868e-01,  3.10384154e-01],\n",
      " [-4.57280695e-01,  3.39476526e-01],\n",
      " [-4.88884568e-01,  4.50980783e-01],\n",
      " ...\n",
      " [-3.02165300e-01,  1.38099536e-01],\n",
      " [-4.62923616e-01,  4.26206917e-01],\n",
      " [-4.32233781e-01,  3.98858726e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 10/51 [00:01<00:05,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.515215), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.16173190e-01,  3.67528975e-01],\n",
      " [-1.54113248e-01,  5.46912253e-02],\n",
      " [-4.98598695e-01,  4.55839038e-01],\n",
      " ...\n",
      " [-4.24640715e-01,  4.07704920e-01],\n",
      " [-4.82481331e-01,  4.42799777e-01],\n",
      " [-4.00273710e-01,  3.68549049e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.471427), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.48884219e-01,  4.24878508e-01],\n",
      " [-4.22148883e-01,  3.98335278e-01],\n",
      " [-4.17299330e-01,  3.82410556e-01],\n",
      " ...\n",
      " [-4.67937052e-01,  3.32132280e-01],\n",
      " [-4.67004389e-01,  4.27959681e-01],\n",
      " [-4.50103462e-01,  3.89334291e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/51 [00:01<00:04,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.741884), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-3.00859153e-01,  2.36551195e-01],\n",
      " [-4.33273673e-01,  4.16352183e-01],\n",
      " [-4.78516161e-01,  4.30571407e-01],\n",
      " ...\n",
      " [-4.37720001e-01,  4.15572107e-01],\n",
      " [-4.22734588e-01,  3.92147183e-01],\n",
      " [-4.06612217e-01,  3.77490669e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.565363), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.62611496e-01,  4.17690605e-01],\n",
      " [-4.36854541e-01,  4.12630349e-01],\n",
      " [-3.94904047e-01,  3.58088404e-01],\n",
      " ...\n",
      " [-4.50190842e-01,  4.01198775e-01],\n",
      " [-4.39440668e-01,  4.04438734e-01],\n",
      " [-4.45745289e-01,  4.02513593e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 14/51 [00:02<00:04,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.493599), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-3.99017572e-01,  3.86015534e-01],\n",
      " [-3.36442947e-01,  2.15022236e-01],\n",
      " [-4.33015674e-01,  3.94012302e-01],\n",
      " ...\n",
      " [-1.63430333e-01,  1.28331274e-01],\n",
      " [-4.20222968e-01,  3.94243687e-01],\n",
      " [-5.09769022e-01,  4.67697918e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.650402), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.40109074e-01,  4.04699266e-01],\n",
      " [-4.83906627e-01,  3.57710093e-01],\n",
      " [-4.13776964e-01,  3.91910017e-01],\n",
      " ...\n",
      " [-4.32631403e-01,  4.12915111e-01],\n",
      " [-4.20505941e-01,  3.76066357e-01],\n",
      " [-4.59740907e-01,  4.05771136e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 16/51 [00:02<00:04,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.595098), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-3.56078237e-01,  2.57252842e-01],\n",
      " [-2.62651682e-01,  2.16311142e-01],\n",
      " [-4.04502720e-01,  3.52889985e-01],\n",
      " ...\n",
      " [-4.39156383e-01,  4.17638689e-01],\n",
      " [-4.08964843e-01,  3.33174080e-01],\n",
      " [-4.66579318e-01,  4.43179727e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.586326), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-3.96455318e-01,  2.85423458e-01],\n",
      " [-3.94685060e-01,  3.57378960e-01],\n",
      " [-4.43657696e-01,  4.25764024e-01],\n",
      " ...\n",
      " [-4.39368337e-01,  4.25206602e-01],\n",
      " [-4.00279045e-01,  3.70454550e-01],\n",
      " [-4.65757936e-01,  4.08726007e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 18/51 [00:02<00:03,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.587899), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-3.56257200e-01,  2.63031185e-01],\n",
      " [-4.27754492e-01,  4.10894632e-01],\n",
      " [-3.66397977e-01,  2.41656378e-01],\n",
      " ...\n",
      " [-4.79896516e-01,  3.92811418e-01],\n",
      " [-4.60112631e-01,  4.42134708e-01],\n",
      " [-4.48412865e-01,  4.10433233e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.845145), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.50965196e-01,  4.00342017e-01],\n",
      " [-2.66492158e-01,  1.83337077e-01],\n",
      " [-4.24219668e-01,  4.02988613e-01],\n",
      " ...\n",
      " [-4.81686920e-01,  4.50510234e-01],\n",
      " [-3.95231038e-01,  3.47871929e-01],\n",
      " [-4.46764827e-01,  4.16915417e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 20/51 [00:02<00:03,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.662792), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.27408606e-01,  3.97102773e-01],\n",
      " [-4.45346951e-01,  3.92804354e-01],\n",
      " [-4.91896719e-01,  4.76324677e-01],\n",
      " ...\n",
      " [-3.61953229e-01,  2.60765165e-01],\n",
      " [-4.16760683e-01,  1.94366038e-01],\n",
      " [-3.83902878e-01,  3.70019883e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.582318), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.50464636e-01,  4.16217834e-01],\n",
      " [-3.24080914e-01,  2.06406295e-01],\n",
      " [-4.49058980e-01,  4.20630157e-01],\n",
      " ...\n",
      " [-4.46159631e-01,  4.17391986e-01],\n",
      " [-4.61646080e-01,  4.13049370e-01],\n",
      " [-4.39842850e-01,  4.09004778e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 22/51 [00:03<00:03,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.464003), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.12048519e-01,  3.87138486e-01],\n",
      " [-4.10455555e-01,  3.73794734e-01],\n",
      " [-4.49912637e-01,  4.07740474e-01],\n",
      " ...\n",
      " [-4.20459479e-01,  3.73218447e-01],\n",
      " [-4.67766732e-01,  4.62281555e-01],\n",
      " [-4.37171906e-01,  3.95031452e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.688791), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-2.87998736e-01,  2.18380079e-01],\n",
      " [-4.82342094e-01,  4.54786569e-01],\n",
      " [-3.97941858e-01,  3.54205668e-01],\n",
      " ...\n",
      " [-4.35498565e-01,  3.75695229e-01],\n",
      " [-4.11678225e-01,  3.86163384e-01],\n",
      " [-4.38215941e-01,  3.85134369e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 24/51 [00:03<00:03,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.652069), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.10438895e-01,  3.93496633e-01],\n",
      " [-4.06403154e-01,  3.72612834e-01],\n",
      " [-4.42836404e-01,  4.16208148e-01],\n",
      " ...\n",
      " [-3.49555522e-01,  2.67065585e-01],\n",
      " [-4.20465350e-01,  3.38019013e-01],\n",
      " [-4.30336267e-01,  3.60679626e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.772382), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.06282991e-01,  3.71205449e-01],\n",
      " [-4.21371728e-01,  3.76226276e-01],\n",
      " [-4.19820040e-01,  4.07925189e-01],\n",
      " ...\n",
      " [-4.69682276e-01,  4.14035112e-01],\n",
      " [-3.94107521e-01,  3.60061228e-01],\n",
      " [-3.99107009e-01,  3.43549579e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 26/51 [00:03<00:02,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.574665), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.83754724e-01,  4.18368161e-01],\n",
      " [-3.77809495e-01,  3.49271536e-01],\n",
      " [-4.24830526e-01,  3.86373818e-01],\n",
      " ...\n",
      " [-4.19329017e-01,  3.66345108e-01],\n",
      " [-4.38694239e-01,  4.14889425e-01],\n",
      " [-4.28369701e-01,  3.95388842e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.554829), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.87972558e-01,  4.39846545e-01],\n",
      " [-4.33771193e-01,  4.00784016e-01],\n",
      " [-2.31300175e-01,  1.13486372e-01],\n",
      " ...\n",
      " [-2.45993450e-01,  1.68264821e-01],\n",
      " [-4.40583348e-01,  4.20513302e-01],\n",
      " [-4.03237581e-01,  3.88736725e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 28/51 [00:03<00:02,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.723188), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-3.18910748e-01,  1.89529091e-01],\n",
      " [-4.60391998e-01,  4.16940749e-01],\n",
      " [-4.40825194e-01,  3.91672641e-01],\n",
      " ...\n",
      " [-4.30557430e-01,  3.92178804e-01],\n",
      " [-4.23881531e-01,  4.02077407e-01],\n",
      " [-4.62230533e-01,  4.27517831e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.566521), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-3.94268066e-01,  3.10270280e-01],\n",
      " [-4.29317147e-01,  3.94929349e-01],\n",
      " [-3.98339540e-01,  3.10636431e-01],\n",
      " ...\n",
      " [-4.40143168e-01,  4.26686168e-01],\n",
      " [-4.78120923e-01,  3.73290032e-01],\n",
      " [-4.14528131e-01,  3.20053250e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 30/51 [00:04<00:02,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.381784), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.19599801e-01,  4.02740747e-01],\n",
      " [-4.45630223e-01,  4.13680464e-01],\n",
      " [-4.37366098e-01,  4.11422312e-01],\n",
      " ...\n",
      " [-4.22838360e-01,  4.09521282e-01],\n",
      " [-4.41224575e-01,  4.10541952e-01],\n",
      " [-2.23211393e-01,  9.30397958e-02]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.697292), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-3.92561227e-01,  2.86075622e-01],\n",
      " [-3.38869363e-01,  2.11932272e-01],\n",
      " [-4.04920220e-01,  3.85669917e-01],\n",
      " ...\n",
      " [-4.51687485e-01,  3.99943471e-01],\n",
      " [-4.09673303e-01,  3.81754965e-01],\n",
      " [-4.66859818e-01,  4.33908254e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 32/51 [00:04<00:02,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.564646), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.69863892e-01,  4.48037982e-01],\n",
      " [-4.09425795e-01,  3.55910212e-01],\n",
      " [-4.67709273e-01,  3.24587584e-01],\n",
      " ...\n",
      " [-3.92611325e-01,  3.71822506e-01],\n",
      " [-4.04227495e-01,  3.71356606e-01],\n",
      " [-4.54564244e-01,  4.06164736e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.64929), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.11486030e-01,  3.95204097e-01],\n",
      " [-4.70284969e-01,  4.28448856e-01],\n",
      " [-4.65870857e-01,  4.20030862e-01],\n",
      " ...\n",
      " [-4.20798540e-01,  3.72232348e-01],\n",
      " [-4.05581236e-01,  3.74520659e-01],\n",
      " [-4.21519220e-01,  3.95226210e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 34/51 [00:04<00:02,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.580377), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.34290886e-01,  2.99220741e-01],\n",
      " [-4.26537216e-01,  3.93974304e-01],\n",
      " [-4.06028390e-01,  3.77872854e-01],\n",
      " ...\n",
      " [-4.04019922e-01,  4.02412742e-01],\n",
      " [-4.10664320e-01,  3.87581468e-01],\n",
      " [-3.78036976e-01,  2.76168376e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.738892), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-2.71705180e-01,  1.76852480e-01],\n",
      " [-4.21570957e-01,  3.95089447e-01],\n",
      " [-4.04880166e-01,  3.72396499e-01],\n",
      " ...\n",
      " [-4.34598953e-01,  3.21092874e-01],\n",
      " [-4.28475916e-01,  3.95067036e-01],\n",
      " [-4.60895270e-01,  4.32680279e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 36/51 [00:04<00:01,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.473307), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-3.98547590e-01,  3.78743082e-01],\n",
      " [-4.74058777e-01,  4.39940572e-01],\n",
      " [-3.55178684e-01,  2.90910959e-01],\n",
      " ...\n",
      " [-2.76037186e-01,  1.42424792e-01],\n",
      " [-3.74241114e-01,  2.60163933e-01],\n",
      " [-3.22061956e-01,  2.00813144e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.572013), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.09533292e-01,  3.82507503e-01],\n",
      " [-4.50669676e-01,  4.34732616e-01],\n",
      " [-4.94459152e-01,  4.37111676e-01],\n",
      " ...\n",
      " [-4.70985979e-01,  4.22222555e-01],\n",
      " [-3.93694311e-01,  3.09712380e-01],\n",
      " [-3.69619817e-01,  3.49629700e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 39/51 [00:05<00:01,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.567469), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.26024646e-01,  3.95389169e-01],\n",
      " [-4.57083434e-01,  4.37024713e-01],\n",
      " [-2.81681359e-01,  1.78317487e-01],\n",
      " ...\n",
      " [-4.37740594e-01,  3.87201071e-01],\n",
      " [-4.52187687e-01,  4.27464008e-01],\n",
      " [-3.95321816e-01,  3.79292607e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.571079), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.89270121e-01,  3.67770612e-01],\n",
      " [-4.41111863e-01,  3.97221744e-01],\n",
      " [-4.38378900e-01,  3.75989765e-01],\n",
      " ...\n",
      " [-3.79099518e-01,  3.66768569e-01],\n",
      " [-4.42182183e-01,  4.00831491e-01],\n",
      " [-4.84298617e-01,  4.38068122e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.755197), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.17310596e-01,  3.77634108e-01],\n",
      " [-4.62735415e-01,  4.23699647e-01],\n",
      " [-4.15376931e-01,  3.86574864e-01],\n",
      " ...\n",
      " [-3.07819694e-01,  1.95270330e-01],\n",
      " [-4.62092936e-01,  4.28554803e-01],\n",
      " [-3.85199189e-01,  2.90536344e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 41/51 [00:05<00:01,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.782985), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.19304699e-01,  3.84417444e-01],\n",
      " [-4.29437220e-01,  3.22912544e-01],\n",
      " [-4.48959202e-01,  3.91854912e-01],\n",
      " ...\n",
      " [-4.70041513e-01,  4.38607663e-01],\n",
      " [-4.50492233e-01,  4.16498095e-01],\n",
      " [-4.47364718e-01,  4.23392028e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.824726), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.17407423e-01,  3.65763366e-01],\n",
      " [-4.19851393e-01,  3.57268661e-01],\n",
      " [-1.11672536e-01,  1.57278255e-02],\n",
      " ...\n",
      " [-4.43542868e-01,  3.86881560e-01],\n",
      " [-4.68210697e-01,  4.42450911e-01],\n",
      " [-4.14441794e-01,  4.16309357e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 44/51 [00:05<00:00,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.45594), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.72225308e-01,  4.44974154e-01],\n",
      " [-4.58721310e-01,  4.15964484e-01],\n",
      " [-4.35054988e-01,  4.07524496e-01],\n",
      " ...\n",
      " [-4.32146162e-01,  4.03927624e-01],\n",
      " [-4.42094624e-01,  4.08201933e-01],\n",
      " [-4.39265847e-01,  3.91646206e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.735047), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.42381203e-01,  4.23409522e-01],\n",
      " [-4.56688941e-01,  4.00610387e-01],\n",
      " [-5.10159910e-01,  4.67349738e-01],\n",
      " ...\n",
      " [-4.58144069e-01,  4.30180013e-01],\n",
      " [-3.41398180e-01,  2.64149994e-01],\n",
      " [-2.74279118e-01,  1.81463733e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.573278), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-3.93023103e-01,  2.81572789e-01],\n",
      " [-4.02590156e-01,  3.11040401e-01],\n",
      " [-4.68603253e-01,  4.34740961e-01],\n",
      " ...\n",
      " [-4.09303457e-01,  3.85117114e-01],\n",
      " [-4.34992909e-01,  4.08543825e-01],\n",
      " [-4.66670364e-01,  4.31824565e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 47/51 [00:05<00:00, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.592777), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-2.11763158e-01,  1.18162133e-01],\n",
      " [-4.85430062e-01,  4.47657615e-01],\n",
      " [-4.25604403e-01,  3.98084164e-01],\n",
      " ...\n",
      " [-4.05361950e-01,  3.82383108e-01],\n",
      " [-4.30735260e-01,  4.04971957e-01],\n",
      " [-4.16345656e-01,  3.95132035e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.698506), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.30772781e-01,  4.00505126e-01],\n",
      " [-4.36725408e-01,  4.07539755e-01],\n",
      " [-4.15126234e-01,  3.85542214e-01],\n",
      " ...\n",
      " [-2.65830487e-01,  2.11293519e-01],\n",
      " [-4.11877513e-01,  4.00073975e-01],\n",
      " [-4.26503062e-01,  3.93677711e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.733483), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.09756750e-01,  3.79970759e-01],\n",
      " [-3.96590412e-01,  3.57603610e-01],\n",
      " [-4.49387968e-01,  4.02345926e-01],\n",
      " ...\n",
      " [-3.80957425e-01,  2.53830492e-01],\n",
      " [-4.07802135e-01,  3.58801723e-01],\n",
      " [-2.39462435e-01,  1.22563139e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 49/51 [00:06<00:00, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.68133), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.33468223e-01,  3.97790104e-01],\n",
      " [-5.41779518e-01,  3.92217547e-01],\n",
      " [-4.65376824e-01,  4.12408322e-01],\n",
      " ...\n",
      " [-4.71589714e-01,  4.51715469e-01],\n",
      " [-4.01877046e-01,  3.57235223e-01],\n",
      " [-4.36540723e-01,  4.10516322e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.589475), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.15849149e-01,  4.02388394e-01],\n",
      " [-4.36504543e-01,  3.98892879e-01],\n",
      " [-4.13278580e-01,  3.98712993e-01],\n",
      " ...\n",
      " [-3.83228809e-01,  3.73265237e-01],\n",
      " [-4.09423411e-01,  3.98320377e-01],\n",
      " [-3.44964504e-01,  2.39860758e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.402563), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.35128182e-01,  2.87692398e-01],\n",
      " [-2.39549458e-01,  1.81342125e-01],\n",
      " [-3.76832008e-01,  2.64526159e-01],\n",
      " ...\n",
      " [-3.73958856e-01,  3.39537024e-01],\n",
      " [-3.99806291e-01,  3.72049510e-01],\n",
      " [-4.13967431e-01,  3.90396804e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:06<00:00,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.593329), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-2.11539447e-01,  1.04477718e-01],\n",
      " [-4.36842561e-01,  4.00366277e-01],\n",
      " [-4.20866191e-01,  3.93352479e-01],\n",
      " ...\n",
      " [-3.39094430e-01,  2.59042680e-01],\n",
      " [-2.10636526e-01,  1.30466431e-01],\n",
      " [-4.56774592e-01,  4.19524759e-01]]), hidden_states=None, attentions=None)\n",
      "epoch=0: train_ppl=Tensor(shape=[], dtype=Float32, value= 1.88749) train_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.635251) eval_ppl=Tensor(shape=[], dtype=Float32, value= 1.85164) eval_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.616073)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from mindnlp.core import value_and_grad\n",
    "import mindspore.nn as nn\n",
    "# training and evaluation\n",
    "\n",
    "def forward_fn(**batch):\n",
    "    outputs = model(**batch)\n",
    "    loss = outputs.loss\n",
    "    return loss\n",
    "\n",
    "# 定义 Softmax 函数，用于评估阶段的归一化\n",
    "softmax = nn.Softmax(axis=-1)\n",
    "\n",
    "# 使用value_and_grad装饰前向传播函数，以便在训练时获取损失值和梯度\n",
    "grad_fn = value_and_grad(forward_fn, model.trainable_params())\n",
    "\n",
    "# 开始训练和评估循环\n",
    "for epoch in range(num_epochs):\n",
    "    # 设置模型为训练模式\n",
    "    model.set_train()\n",
    "    total_loss = 0\n",
    "    train_total_size = train_dataset.get_dataset_size()\n",
    "    # 遍历训练数据集\n",
    "    for step, batch in enumerate(tqdm(train_dataset.create_dict_iterator(), total=train_total_size)):\n",
    "        # 清除上一步的梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 计算损失值和梯度\n",
    "        loss = grad_fn(**batch)\n",
    "         # 更新模型参数\n",
    "        optimizer.step()\n",
    "        # 累加损失值\n",
    "        total_loss += loss.float() #这一步不一样\n",
    "        # 更新学习率调度器\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    # 设置模型为评估模式\n",
    "    model.set_train(False)\n",
    "    eval_loss = 0 #这一步没有\n",
    "    eval_preds = [] #这一步没有\n",
    "    eval_total_size = eval_dataset.get_dataset_size()\n",
    "    # 遍历评估数据集\n",
    "    for step, batch in enumerate(tqdm(eval_dataset.create_dict_iterator(), total=eval_total_size)):\n",
    "        # 禁用梯度计算，进行前向传播\n",
    "        with mindspore._no_grad(): # 没有这句\n",
    "            outputs = model(**batch)\n",
    "        loss = outputs.loss        # 以下都不一样\n",
    "        eval_loss += loss.float()\n",
    "        # 对于序列分类任务，直接获取类别索引\n",
    "        print(f'outputs:{outputs}')\n",
    "        eval_preds.extend(ops.argmax(outputs.logits, -1).asnumpy().tolist())\n",
    "    \n",
    "# 计算评估期损失\n",
    "    eval_epoch_loss = eval_loss / len(eval_dataset)\n",
    "    eval_ppl = ops.exp(eval_epoch_loss)\n",
    "# 计算训练期损失\n",
    "    train_epoch_loss = total_loss / len(train_dataset)\n",
    "    train_ppl = ops.exp(train_epoch_loss)\n",
    "# 打印训练和评估结果\n",
    "    print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=} {eval_ppl=} {eval_epoch_loss=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b95a29e-3b1c-493e-916d-cb7bd5c1f44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_preds=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(f\"{eval_preds=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a913d1b6-f30d-496d-a970-ea097ecd210c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample logits: [[-0.21153945  0.10447772]\n",
      " [-0.43684256  0.40036628]\n",
      " [-0.4208662   0.39335248]\n",
      " [-0.4019394   0.31169894]\n",
      " [-0.4066868   0.36516586]\n",
      " [-0.33909443  0.25904268]\n",
      " [-0.21063653  0.13046643]\n",
      " [-0.4567746   0.41952476]]\n"
     ]
    }
   ],
   "source": [
    "# 打印前5个样本的logits\n",
    "print(f\"Sample logits: {outputs.logits[:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b6c252c-f6d1-41f0-935b-e7b2aed0863f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:279,total:408\n",
      "accuracy=68.38235294117648 % on the evaluation dataset\n",
      "eval_preds[:10]=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "ground_truth[:10]=[1, 0, 0, 1, 0, 1, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# print accuracy\n",
    "# 初始化正确预测和总样本的计数器\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# 初始化用于存储真实标签的列表\n",
    "ground_truth = []\n",
    "\n",
    "# 遍历预测结果和验证数据集\n",
    "for pred, data in zip(eval_preds, datasets['validation'].create_dict_iterator(output_numpy=True)):\n",
    "    # 获取真实的文本标签\n",
    "    true = int(data['label'])\n",
    "    # 将真实标签添加到ground_truth列表中\n",
    "    ground_truth.append(true)\n",
    "    # 如果预测的标签与真实标签一致，则正确计数器加一\n",
    "    if pred == true:\n",
    "        correct += 1\n",
    "    # 总样本计数器加一\n",
    "    total += 1\n",
    "print(f'correct:{correct},total:{total}')\n",
    "# 计算准确率\n",
    "accuracy = correct / total * 100\n",
    "# 输出准确率\n",
    "print(f\"{accuracy=} % on the evaluation dataset\")\n",
    "# 输出前10个预测结果\n",
    "print(f\"{eval_preds[:10]=}\")\n",
    "# 输出前10个真实标签\n",
    "print(f\"{ground_truth[:10]=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77adfbb0-f8fc-43e0-aad2-42d7f604cbf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <mindspore.dataset.engine.datasets_user_defined.GeneratorDataset at 0xffff8436df40>,\n",
       " 'validation': <mindspore.dataset.engine.datasets_user_defined.GeneratorDataset at 0xfffdfc07d550>,\n",
       " 'test': <mindspore.dataset.engine.datasets_user_defined.GeneratorDataset at 0xfffdfc07d310>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26e88eb1-3d24-488b-ad62-0c18b81b861e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tensor(shape=[8, 73], dtype=Int64, value=\n",
       " [[    0,   894,    26 ...     1,     1,     1],\n",
       "  [    0, 43600,  1322 ...     1,     1,     1],\n",
       "  [    0,   133,  1404 ...   135,   479,     2],\n",
       "  ...\n",
       "  [    0, 30888,    12 ...     1,     1,     1],\n",
       "  [    0,  5771,   385 ...     1,     1,     1],\n",
       "  [    0,   713, 33752 ...     1,     1,     1]]),\n",
       " Tensor(shape=[8, 73], dtype=Int64, value=\n",
       " [[1, 1, 1 ... 0, 0, 0],\n",
       "  [1, 1, 1 ... 0, 0, 0],\n",
       "  [1, 1, 1 ... 1, 1, 1],\n",
       "  ...\n",
       "  [1, 1, 1 ... 0, 0, 0],\n",
       "  [1, 1, 1 ... 0, 0, 0],\n",
       "  [1, 1, 1 ... 0, 0, 0]]),\n",
       " Tensor(shape=[8], dtype=Int64, value= [1, 0, 0, 1, 0, 1, 0, 1])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取数据集迭代器的下一个元素\n",
    "next(eval_dataset.create_tuple_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8de6005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "# 构建PEFT模型的唯一标识符\n",
    "# 该标识符结合了模型名称或路径、PEFT配置的类型和任务类型，用于区分不同的PEFT模型\n",
    "peft_model_id = f\"{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}\"\n",
    "\n",
    "# 保存预训练的PEFT模型\n",
    "# 使用构建的PEFT模型标识符作为模型ID，将模型保存到指定目录或路径\n",
    "model.save_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd20cd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.7M\troberta-large_IA3_SEQ_CLS/adapter_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# 构建checkpoint文件的路径\n",
    "ckpt = f\"{peft_model_id}/adapter_model.ckpt\"\n",
    "# 使用shell命令检查checkpoint文件的大小\n",
    "!du -h $ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76c2fc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 导入Peft模型和配置相关的模块\n",
    "from mindnlp.peft import PeftModel, PeftConfig\n",
    "\n",
    "# 构造Peft模型的唯一标识符\n",
    "# 这里使用模型名称或路径、Peft配置的类型和任务类型来组合成一个字符串\n",
    "peft_model_id = f\"{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}\"\n",
    "\n",
    "# 从预训练的Peft模型中加载配置\n",
    "# 这里的配置将指导如何加载和使用Peft模型\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "# 从配置中加载基础模型\n",
    "# 这个基础模型是用于执行序列到序列语言模型任务的\n",
    "model = AutoModelForSequenceClassification.from_pretrained(config.base_model_name_or_path)\n",
    "# 使用Peft模型对基础模型进行微调\n",
    "# 这一步是将基础模型与Peft模型的特定微调参数结合起来\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37d712ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examle:{'input_ids': array([[    0,   894,    26,     5,   689, 11131, 11637,   265,   630,\n",
      "          128,    90,  2564,     5,   138,   128,    29,   251,    12,\n",
      "         1279,   434,  1860,   479,     2,     2,   113,    20,   689,\n",
      "        11131, 11637,   265,   473,    45,  2564,    84,   251,    12,\n",
      "         1279,   434,  1860,   479,     2,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1],\n",
      "       [    0, 43600,  1322, 10054,    26, 14822,   636,  1242, 19975,\n",
      "            5,  7780,  4304,     8,  1415,   556,     7,   634,    39,\n",
      "          251,   107,     9,  1058,    11,     5,   997,   479,     2,\n",
      "            2,  9962,  1141,    26,    37,    21,    22,   727,   135,\n",
      "          639,  1655,  3516,    22,     8,  1415,   556,     7,   634,\n",
      "           39,   107,     9,  1058,    11,     5,   997,   479,     2,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1],\n",
      "       [    0,   133,  1404,    21,    23, 15966,     4,  6617,  4796,\n",
      "          136,     5,  4796,  2156,  3269,    15,     5,  1852,  2156,\n",
      "            8,    23,   112,     4,  2517,  6468,   136,     5,  5092,\n",
      "        13638,  2156,    67,  3269,   479,     2,     2,   133,  1404,\n",
      "           21,    23, 15966,     4,  5479,  4796, 14621,   975,  5457,\n",
      "         2156,  8077,  3269,    15,     5,  1852,  2156,     8,    23,\n",
      "          112,     4,  2517,  5339,   136,     5,  5092, 13638,  3858,\n",
      "          597,  5457,  2156,   159,   321,     4,   134,   135,   479,\n",
      "            2],\n",
      "       [    0,   133, 16305,    12,   347,  6454,    16,  2445,   454,\n",
      "          779,     7,  2845,   114,    24,    40, 18839,    10,  1984,\n",
      "          479,     2,     2,   133, 16305,    12,   347,  6454,   585,\n",
      "          307,    14,    24,    40,  2845,    11,   779,   549,     7,\n",
      "        18839,    10,  1984,   137,     5, 19050,   479,     2,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1],\n",
      "       [    0,  3084,  5461,    33,    57,   278,    13,     5,  2366,\n",
      "           50,     5,  1837,  1500,   479,     2,     2,  3084,  5461,\n",
      "           33,    57,   278,    13,     5,  1837,    50,  2366,  1200,\n",
      "         2156,    53, 18966,   607,    34,  4407,    45,  2181,   479,\n",
      "            2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1],\n",
      "       [    0, 30888,    12, 13012,    26,    24,    74,  1649,    70,\n",
      "            9,    63,   153,    12,  7269,  1897,  1138,     7,  1306,\n",
      "           51,    58,  7818,  7460,   479,     2,     2,   243,    34,\n",
      "           67,    26,    24,    74,  1551,    70,     9,    63,  1897,\n",
      "         1321,    55,    87,   112,   153,     7,  1306,    51,    33,\n",
      "         1030,  2194,   479,     2,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1],\n",
      "       [    0,  5771,   385, 44882,   179,  1389,    11,     5,  1737,\n",
      "           58,    62,    94,    76,  2156,    51,    33,  1882,    30,\n",
      "         3337,   135,   187,     5,  6200,    29,  2156,    26,  7233,\n",
      "         3056,   479,     2,     2,   133,  2534,    26,   385, 44882,\n",
      "          179,  1389,    11,     5,  1737,    33,  4491,    30,    25,\n",
      "          203,    25,  5553,   135,   187,     5,  6200,    29,   479,\n",
      "            2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1],\n",
      "       [    0,   713, 33752,    19, 42083, 11834,  4591, 27576,     8,\n",
      "         2386,  5485,     7,   173,    11,  2800,  7952,     9, 24549,\n",
      "         2156, 25878,   230,   849,     8, 25878, 17255,   479, 13548,\n",
      "            4,     2,     2,  8863,   448,    26,     5, 42083,   785,\n",
      "           58,    67,  6818,    19, 42083, 11834,  4591, 27576,  2156,\n",
      "           61,  2386,  5485,     7,   173,    11, 24549,  2156, 25878,\n",
      "          230,   849,     8, 25878, 46255,   479, 15721,     4,     2,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1]], dtype=int64), 'attention_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0]], dtype=int64), 'labels': array([1, 0, 0, 1, 0, 1, 0, 1], dtype=int64)}\n",
      "[1 0 0 1 0 1 0 1]\n",
      "Inputs:{'input_ids': Tensor(shape=[1, 12], dtype=Int64, value=\n",
      "[[    0, 10975,   134 ...   112,   742,     2]]), 'attention_mask': Tensor(shape=[1, 12], dtype=Int64, value=\n",
      "[[1, 1, 1 ... 1, 1, 1]])}\n",
      "Outputs:[1 1 1 1 1 1 1 1]\n",
      "Sample 1: Similar\n",
      "Sample 2: Similar\n",
      "Sample 3: Similar\n",
      "Sample 4: Similar\n",
      "Sample 5: Similar\n",
      "Sample 6: Similar\n",
      "Sample 7: Similar\n",
      "Sample 8: Similar\n"
     ]
    }
   ],
   "source": [
    "# 设置模型为评估模式，以禁用dropout等训练时的行为\n",
    "model.set_train(False)\n",
    "# 从验证数据集中获取一个样本，以便后续进行推理演示\n",
    "example = next(eval_dataset.create_dict_iterator(output_numpy=True))\n",
    "\n",
    "# 打印样本'input_ids'、'attention_mask'和'labels'\n",
    "print(f\"Examle:{example}\")\n",
    "# 打印样本中的文本标签，以便用户了解正在处理的数据\n",
    "print(example['labels'])\n",
    "# 使用tokenizer对样本文本进行编码，以将其转换为模型可处理的输入格式\n",
    "inputs = tokenizer(example['labels'], return_tensors=\"ms\")\n",
    "# 打印编码后的输入，以展示输入格式和内容\n",
    "print(f\"Inputs:{inputs}\")\n",
    "\n",
    "# 禁用梯度计算，以减少计算资源消耗，因为推理过程不需要反向传播\n",
    "with mindspore._no_grad():\n",
    "    # 使用模型生成分类结果\n",
    "    outputs = model(**batch)\n",
    "    outputs = outputs.logits.argmax(axis=-1)\n",
    "    # 打印生成的分类结果\n",
    "    print(f\"Outputs:{outputs}\")\n",
    "    \n",
    "    # 根据MRPC数据集的定义，0代表不相似，1代表相似。将生成的分类结果转换回人类可读的文本格式，并打印\n",
    "    label_names = ['Dissimilar', 'Similar']\n",
    "    \n",
    "    # 获取每个样本的最大概率对应的类别索引\n",
    "    predicted_class_indices = outputs.asnumpy()\n",
    "    \n",
    "    # 将类别索引转换为人类可读的标签\n",
    "    predicted_labels = [label_names[index] for index in predicted_class_indices]\n",
    "    \n",
    "    # 打印分类结果\n",
    "    for i, label in enumerate(predicted_labels):\n",
    "        print(f\"Sample {i+1}: {label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
