{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e865045",
   "metadata": {},
   "source": [
    "IA3配条代码参考自：\n",
    "\n",
    "[peft_ia3_mindnlp.ipynb](https://github.com/mindspore-lab/mindnlp/tree/master/llm/peft/ia3/seq_2_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1abbd02",
   "metadata": {},
   "source": [
    "模型配置参考：基于MindSpore NLP的Roberta模型Prompt Tuning\n",
    "\n",
    "https://blog.csdn.net/Kenji_Shinji/article/details/144395136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f93b7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.323 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mindspore\n",
    "from mindnlp.transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from mindnlp.peft import get_peft_config, get_peft_model, get_peft_model_state_dict, LoraConfig, TaskType,IA3Config\n",
    "from mindnlp.dataset import load_dataset\n",
    "from mindnlp.core import ops\n",
    "from mindnlp.common.optimization import get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "from mindnlp import evaluate\n",
    "\n",
    "model_name_or_path = \"roberta-large\"\n",
    "tokenizer_name_or_path = \"roberta-large\"\n",
    "\n",
    "# checkpoint_name = \"financial_sentiment_analysis_lora_v1.ckpt\"\n",
    "checkpoint_name = \"RoBERTa_IA3_v1.ckpt\"\n",
    "\n",
    "# 优化训练表现可以调整以下数值\n",
    "max_length = 128\n",
    "lr = 3e-5\n",
    "num_epochs = 5\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d0850ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MS_ALLOC_CONF]Runtime config:  enable_vmm:True  vmm_align_size:2MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,223,682 || all params: 356,585,476 || trainable%: 0.34316652874555104\n"
     ]
    }
   ],
   "source": [
    "# creating model\n",
    "peft_config = IA3Config(task_type=TaskType.SEQ_CLS, inference_mode=False) #TaskType从SEQ_2_SEQ_LM修改为SEQ_CLS\n",
    "#TaskType.SEQ_2_SEQ_LM 是专门为序列到序列生成任务（如机器翻译、文本摘要等）设计的。对于 RoBERTa 模型和 AutoModelForSequenceClassification，你应该将 task_type 设置为 TaskType.SEQ_CLS，因为这是针对序列分类任务的正确配置。\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, return_dict=True) #对应修改为AutoModelForSequenceClassification\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f9579f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindnlp/transformers/tokenization_utils_base.py:1526: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted, and will be then set to `False` by default. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#加载tokenizer\n",
    "if any(k in model_name_or_path for k in (\"gpt\", \"opt\", \"bloom\")):\n",
    "    padding_side = \"left\"\n",
    "else:\n",
    "    padding_side = \"right\"\n",
    " \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, padding_side=padding_side)\n",
    "if getattr(tokenizer, \"pad_token_id\") is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee2babf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence1': Tensor(shape=[], dtype=String, value= 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .'), 'sentence2': Tensor(shape=[], dtype=String, value= 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'), 'label': Tensor(shape=[], dtype=Int64, value= 1), 'idx': Tensor(shape=[], dtype=Int64, value= 0)}\n"
     ]
    }
   ],
   "source": [
    "# mindspore.dataset.config.set_seed(123)\n",
    "# loading dataset\n",
    "# dataset = load_dataset(\"financial_phrasebank\", \"sentences_allagree\")\n",
    "datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "print(next(datasets['train'].create_dict_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f226e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindnlp.dataset import BaseMapFunction\n",
    " \n",
    "class MapFunc(BaseMapFunction):\n",
    "    def __call__(self, sentence1, sentence2, label, idx):\n",
    "        outputs = tokenizer(sentence1, sentence2, truncation=True, max_length=None)\n",
    "        return outputs['input_ids'], outputs['attention_mask'], label\n",
    " \n",
    "def get_dataset(dataset, tokenizer):\n",
    "    input_colums=['sentence1', 'sentence2', 'label', 'idx']\n",
    "    output_columns=['input_ids', 'attention_mask', 'labels']\n",
    "    dataset = dataset.map(MapFunc(input_colums, output_columns),\n",
    "                          input_colums, output_columns)\n",
    "    dataset = dataset.padded_batch(batch_size, pad_info={'input_ids': (None, tokenizer.pad_token_id),\n",
    "                                                         'attention_mask': (None, 0)})\n",
    "    return dataset\n",
    " \n",
    "train_dataset = get_dataset(datasets['train'], tokenizer)\n",
    "eval_dataset = get_dataset(datasets['validation'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13ea3fc6-f1aa-486f-a81a-9f41cc7ef5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': Tensor(shape=[8, 67], dtype=Int64, value=\n",
      "[[    0, 10127,  1001 ...     1,     1,     1],\n",
      " [    0,   975, 26802 ...     1,     1,     1],\n",
      " [    0,  1213,    56 ...     1,     1,     1],\n",
      " ...\n",
      " [    0,  9064, 32497 ...     1,     1,     1],\n",
      " [    0,   133,  4417 ...     1,     1,     1],\n",
      " [    0,   133, 19888 ...     1,     1,     1]]), 'attention_mask': Tensor(shape=[8, 67], dtype=Int64, value=\n",
      "[[1, 1, 1 ... 0, 0, 0],\n",
      " [1, 1, 1 ... 0, 0, 0],\n",
      " [1, 1, 1 ... 0, 0, 0],\n",
      " ...\n",
      " [1, 1, 1 ... 0, 0, 0],\n",
      " [1, 1, 1 ... 0, 0, 0],\n",
      " [1, 1, 1 ... 0, 0, 0]]), 'labels': Tensor(shape=[8], dtype=Int64, value= [1, 0, 1, 0, 1, 1, 0, 1])}\n"
     ]
    }
   ],
   "source": [
    "print(next(train_dataset.create_dict_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e052eea-f6d6-4a22-a71a-bef47abafffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"glue\", \"mrpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f733a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindnlp.core import optim\n",
    "# optimizer and lr scheduler\n",
    "optimizer = optim.AdamW(model.trainable_params(), lr=lr)\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=(len(train_dataset) * num_epochs),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e65888-89b1-4f12-ad54-c2eeeed6756d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 459/459 [02:41<00:00,  2.84it/s]\n",
      "  2%|▏         | 1/51 [00:00<00:15,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/51 [00:00<00:13,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/51 [00:00<00:10,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/51 [00:01<00:06,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 10/51 [00:01<00:04,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 12/51 [00:01<00:04,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 16/51 [00:02<00:03,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 18/51 [00:02<00:03,  9.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 22/51 [00:02<00:02, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 24/51 [00:02<00:02, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 28/51 [00:03<00:02, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 30/51 [00:03<00:02, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 34/51 [00:03<00:01, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 36/51 [00:04<00:01, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 40/51 [00:04<00:01, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 42/51 [00:04<00:00, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 46/51 [00:05<00:00, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 48/51 [00:05<00:00, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:05<00:00,  9.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "epoch=0: train_ppl=Tensor(shape=[], dtype=Float32, value= 1.89222) train_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.637748) eval_ppl=Tensor(shape=[], dtype=Float32, value= 1.85768) eval_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.619326)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 459/459 [02:28<00:00,  3.10it/s]\n",
      "  2%|▏         | 1/51 [00:00<00:15,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/51 [00:00<00:12,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/51 [00:00<00:10,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/51 [00:01<00:06,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 10/51 [00:01<00:04,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 12/51 [00:01<00:04,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 16/51 [00:02<00:03, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 18/51 [00:02<00:03, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 22/51 [00:02<00:02, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 24/51 [00:02<00:02, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 28/51 [00:03<00:02, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 30/51 [00:03<00:01, 10.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 34/51 [00:03<00:01, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 36/51 [00:03<00:01, 10.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 40/51 [00:04<00:00, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 42/51 [00:04<00:00, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 46/51 [00:04<00:00, 11.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 48/51 [00:04<00:00, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:05<00:00,  9.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "epoch=1: train_ppl=Tensor(shape=[], dtype=Float32, value= 1.87218) train_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.627105) eval_ppl=Tensor(shape=[], dtype=Float32, value= 1.84859) eval_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.614423)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 459/459 [02:31<00:00,  3.04it/s]\n",
      "  2%|▏         | 1/51 [00:00<00:15,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/51 [00:00<00:13,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 5/51 [00:00<00:07,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 7/51 [00:01<00:05,  7.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/51 [00:01<00:04,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 13/51 [00:01<00:03,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 17/51 [00:02<00:03, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 19/51 [00:02<00:02, 10.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 23/51 [00:02<00:02, 11.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 25/51 [00:02<00:02, 11.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 29/51 [00:03<00:01, 11.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n",
      "ops.argmax(outputs.logits, -1)=Tensor(shape=[8], dtype=Int64, value= [1, 1, 1, 1, 1, 1, 1, 1]): ops.argmax(outputs.logits, -1).asnumpy()=array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) ops.argmax(outputs.logits, -1).asnumpy().tolist()=[1, 1, 1, 1, 1, 1, 1, 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 31/51 [00:03<00:01, 11.26it/s]"
     ]
    }
   ],
   "source": [
    "from mindnlp.core import value_and_grad\n",
    "# training and evaluation\n",
    "\n",
    "def forward_fn(**batch):\n",
    "    outputs = model(**batch)\n",
    "    loss = outputs.loss\n",
    "    return loss\n",
    "\n",
    "# 使用value_and_grad装饰前向传播函数，以便在训练时获取损失值和梯度\n",
    "grad_fn = value_and_grad(forward_fn, model.trainable_params())\n",
    "\n",
    "# 开始训练和评估循环\n",
    "for epoch in range(num_epochs):\n",
    "    # 设置模型为训练模式\n",
    "    model.set_train()\n",
    "    total_loss = 0\n",
    "    train_total_size = train_dataset.get_dataset_size()\n",
    "    # 遍历训练数据集\n",
    "    for step, batch in enumerate(tqdm(train_dataset.create_dict_iterator(), total=train_total_size)):\n",
    "        # 清除上一步的梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 计算损失值和梯度\n",
    "        loss = grad_fn(**batch)\n",
    "         # 更新模型参数\n",
    "        optimizer.step()\n",
    "        # 累加损失值\n",
    "        total_loss += loss.float() #这一步不一样\n",
    "        # 更新学习率调度器\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    # 设置模型为评估模式\n",
    "    model.set_train(False)\n",
    "    eval_loss = 0 #这一步没有\n",
    "    eval_preds = [] #这一步没有\n",
    "    eval_total_size = eval_dataset.get_dataset_size()\n",
    "    # 遍历评估数据集\n",
    "    for step, batch in enumerate(tqdm(eval_dataset.create_dict_iterator(), total=eval_total_size)):\n",
    "        # 禁用梯度计算，进行前向传播\n",
    "        with mindspore._no_grad(): # 没有这句\n",
    "            outputs = model(**batch)\n",
    "        loss = outputs.loss        # 以下都不一样\n",
    "        eval_loss += loss.float()\n",
    "         # 将模型预测结果解码为文本并存储\n",
    "        #eval_preds.extend(\n",
    "        #    tokenizer.batch_decode(ops.argmax(outputs.logits, -1).asnumpy(), skip_special_tokens=True)\n",
    "        #)\n",
    "\n",
    "        # 对于序列分类任务，直接获取类别索引\n",
    "        print(f\"{ops.argmax(outputs.logits, -1)=}: {ops.argmax(outputs.logits, -1).asnumpy()=} {ops.argmax(outputs.logits, -1).asnumpy().tolist()=} \")\n",
    "        eval_preds.extend(ops.argmax(outputs.logits, -1).asnumpy().tolist())\n",
    "    \n",
    "# 计算评估期损失\n",
    "    eval_epoch_loss = eval_loss / len(eval_dataset)\n",
    "    eval_ppl = ops.exp(eval_epoch_loss)\n",
    "# 计算训练期损失\n",
    "    train_epoch_loss = total_loss / len(train_dataset)\n",
    "    train_ppl = ops.exp(train_epoch_loss)\n",
    "# 打印训练和评估结果\n",
    "    print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=} {eval_ppl=} {eval_epoch_loss=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b95a29e-3b1c-493e-916d-cb7bd5c1f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{eval_preds=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a913d1b6-f30d-496d-a970-ea097ecd210c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印前5个样本的logits\n",
    "print(f\"Sample logits: {outputs.logits[:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6c252c-f6d1-41f0-935b-e7b2aed0863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print accuracy\n",
    "# 初始化正确预测和总样本的计数器\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# 初始化用于存储真实标签的列表\n",
    "ground_truth = []\n",
    "\n",
    "# 遍历预测结果和验证数据集\n",
    "for pred, data in zip(eval_preds, datasets['validation'].create_dict_iterator(output_numpy=True)):\n",
    "    # 获取真实的文本标签\n",
    "    true = str(data['label'])\n",
    "    # 将真实标签添加到ground_truth列表中\n",
    "    ground_truth.append(true)\n",
    "    # 如果预测的标签与真实标签一致，则正确计数器加一\n",
    "    if pred.strip() == true.strip():\n",
    "        correct += 1\n",
    "    # 总样本计数器加一\n",
    "    total += 1\n",
    "# 计算准确率\n",
    "accuracy = correct / total * 100\n",
    "# 输出准确率\n",
    "print(f\"{accuracy=} % on the evaluation dataset\")\n",
    "# 输出前10个预测结果\n",
    "print(f\"{eval_preds[:10]=}\")\n",
    "# 输出前10个真实标签\n",
    "print(f\"{ground_truth[:10]=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77adfbb0-f8fc-43e0-aad2-42d7f604cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e88eb1-3d24-488b-ad62-0c18b81b861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取数据集迭代器的下一个元素\n",
    "next(eval_dataset.create_tuple_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8de6005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "# 构建PEFT模型的唯一标识符\n",
    "# 该标识符结合了模型名称或路径、PEFT配置的类型和任务类型，用于区分不同的PEFT模型\n",
    "peft_model_id = f\"{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}\"\n",
    "\n",
    "# 保存预训练的PEFT模型\n",
    "# 使用构建的PEFT模型标识符作为模型ID，将模型保存到指定目录或路径\n",
    "model.save_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd20cd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建checkpoint文件的路径\n",
    "ckpt = f\"{peft_model_id}/adapter_model.ckpt\"\n",
    "# 使用shell命令检查checkpoint文件的大小\n",
    "!du -h $ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c2fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入Peft模型和配置相关的模块\n",
    "from mindnlp.peft import PeftModel, PeftConfig\n",
    "\n",
    "# 构造Peft模型的唯一标识符\n",
    "# 这里使用模型名称或路径、Peft配置的类型和任务类型来组合成一个字符串\n",
    "peft_model_id = f\"{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}\"\n",
    "\n",
    "# 从预训练的Peft模型中加载配置\n",
    "# 这里的配置将指导如何加载和使用Peft模型\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "# 从配置中加载基础模型\n",
    "# 这个基础模型是用于执行序列到序列语言模型任务的\n",
    "model = AutoModelForSequenceClassification.from_pretrained(config.base_model_name_or_path)\n",
    "# 使用Peft模型对基础模型进行微调\n",
    "# 这一步是将基础模型与Peft模型的特定微调参数结合起来\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d712ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置模型为评估模式，以禁用dropout等训练时的行为\n",
    "model.set_train(False)\n",
    "# 从验证数据集中获取一个样本，以便后续进行推理演示\n",
    "example = next(datasets['validation'].create_dict_iterator(output_numpy=True))\n",
    "\n",
    "# 打印样本中的文本标签，以便用户了解正在处理的数据\n",
    "print(example['idx'])\n",
    "# 使用tokenizer对样本文本进行编码，以将其转换为模型可处理的输入格式\n",
    "inputs = tokenizer(example['idx'], return_tensors=\"ms\")\n",
    "# 打印编码后的输入，以展示输入格式和内容\n",
    "print(inputs)\n",
    "\n",
    "# 禁用梯度计算，以减少计算资源消耗，因为推理过程不需要反向传播\n",
    "with mindspore._no_grad():\n",
    "    # 使用模型生成文本，指定最大新生成的令牌数量以限制输出长度\n",
    "    outputs = model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=10)\n",
    "    # 打印生成的文本编码，以展示模型的输出内容\n",
    "    print(outputs)\n",
    "    # 将生成的文本编码转换回人类可读的文本格式，并打印\n",
    "    print(tokenizer.batch_decode(outputs.asnumpy(), skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
