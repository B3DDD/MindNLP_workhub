{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e865045",
   "metadata": {},
   "source": [
    "IA3配条代码参考自：\n",
    "\n",
    "[peft_ia3_mindnlp.ipynb](https://github.com/mindspore-lab/mindnlp/tree/master/llm/peft/ia3/seq_2_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1abbd02",
   "metadata": {},
   "source": [
    "模型配置参考：基于MindSpore NLP的Roberta模型Prompt Tuning\n",
    "\n",
    "https://blog.csdn.net/Kenji_Shinji/article/details/144395136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f93b7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.293 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mindspore\n",
    "from mindnlp.transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import mindnlp.peft as peft\n",
    "from mindnlp.peft import get_peft_config, get_peft_model, get_peft_model_state_dict, LoraConfig, TaskType,IA3Config\n",
    "from mindnlp.dataset import load_dataset\n",
    "from mindnlp.core.optim import AdamW\n",
    "from mindnlp.core import ops\n",
    "from mindnlp.common.optimization import get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "from mindnlp import evaluate\n",
    "\n",
    "model_name_or_path = \"roberta-large\"\n",
    "tokenizer_name_or_path = \"roberta-large\"\n",
    "\n",
    "# checkpoint_name = \"financial_sentiment_analysis_lora_v1.ckpt\"\n",
    "checkpoint_name = \"RoBERTa_IA3_v1.ckpt\"\n",
    "\n",
    "# 优化训练表现可以调整以下数值\n",
    "max_length = 128\n",
    "lr = 1e-3\n",
    "num_epochs = 3\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d0850ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MS_ALLOC_CONF]Runtime config:  enable_vmm:True  vmm_align_size:2MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,223,682 || all params: 356,585,476 || trainable%: 0.34316652874555104\n"
     ]
    }
   ],
   "source": [
    "# creating model\n",
    "peft_config = peft.IA3Config(task_type=TaskType.SEQ_CLS, inference_mode=False) #TaskType从SEQ_2_SEQ_LM修改为SEQ_CLS\n",
    "#TaskType.SEQ_2_SEQ_LM 是专门为序列到序列生成任务（如机器翻译、文本摘要等）设计的。对于 RoBERTa 模型和 AutoModelForSequenceClassification，你应该将 task_type 设置为 TaskType.SEQ_CLS，因为这是针对序列分类任务的正确配置。\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, return_dict=True) #对应修改为AutoModelForSequenceClassification\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f9579f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindnlp/transformers/tokenization_utils_base.py:1526: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted, and will be then set to `False` by default. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#加载tokenizer\n",
    "if any(k in model_name_or_path for k in (\"gpt\", \"opt\", \"bloom\")):\n",
    "    padding_side = \"left\"\n",
    "else:\n",
    "    padding_side = \"right\"\n",
    " \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, padding_side=padding_side)\n",
    "if getattr(tokenizer, \"pad_token_id\") is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee2babf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence1': Tensor(shape=[], dtype=String, value= 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .'), 'sentence2': Tensor(shape=[], dtype=String, value= 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'), 'label': Tensor(shape=[], dtype=Int64, value= 1), 'idx': Tensor(shape=[], dtype=Int64, value= 0)}\n"
     ]
    }
   ],
   "source": [
    "# mindspore.dataset.config.set_seed(123)\n",
    "# loading dataset\n",
    "# dataset = load_dataset(\"financial_phrasebank\", \"sentences_allagree\")\n",
    "datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "print(next(datasets['train'].create_dict_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f226e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindnlp.dataset import BaseMapFunction\n",
    " \n",
    "class MapFunc(BaseMapFunction):\n",
    "    def __call__(self, sentence1, sentence2, label, idx):\n",
    "        outputs = tokenizer(sentence1, sentence2, truncation=True, max_length=None)\n",
    "        return outputs['input_ids'], outputs['attention_mask'], label\n",
    " \n",
    "def get_dataset(dataset, tokenizer):\n",
    "    input_colums=['sentence1', 'sentence2', 'label', 'idx']\n",
    "    output_columns=['input_ids', 'attention_mask', 'labels']\n",
    "    dataset = dataset.map(MapFunc(input_colums, output_columns),\n",
    "                          input_colums, output_columns)\n",
    "    dataset = dataset.padded_batch(batch_size, pad_info={'input_ids': (None, tokenizer.pad_token_id),\n",
    "                                                         'attention_mask': (None, 0)})\n",
    "    return dataset\n",
    " \n",
    "train_dataset = get_dataset(datasets['train'], tokenizer)\n",
    "eval_dataset = get_dataset(datasets['validation'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13ea3fc6-f1aa-486f-a81a-9f41cc7ef5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': Tensor(shape=[8, 67], dtype=Int64, value=\n",
      "[[    0, 10127,  1001 ...     1,     1,     1],\n",
      " [    0,   975, 26802 ...     1,     1,     1],\n",
      " [    0,  1213,    56 ...     1,     1,     1],\n",
      " ...\n",
      " [    0,  9064, 32497 ...     1,     1,     1],\n",
      " [    0,   133,  4417 ...     1,     1,     1],\n",
      " [    0,   133, 19888 ...     1,     1,     1]]), 'attention_mask': Tensor(shape=[8, 67], dtype=Int64, value=\n",
      "[[1, 1, 1 ... 0, 0, 0],\n",
      " [1, 1, 1 ... 0, 0, 0],\n",
      " [1, 1, 1 ... 0, 0, 0],\n",
      " ...\n",
      " [1, 1, 1 ... 0, 0, 0],\n",
      " [1, 1, 1 ... 0, 0, 0],\n",
      " [1, 1, 1 ... 0, 0, 0]]), 'labels': Tensor(shape=[8], dtype=Int64, value= [1, 0, 1, 0, 1, 1, 0, 1])}\n"
     ]
    }
   ],
   "source": [
    "print(next(train_dataset.create_dict_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e052eea-f6d6-4a22-a71a-bef47abafffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"glue\", \"mrpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e01b3c38-3d33-4953-8a8b-9c89465a68da",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(params=model.trainable_params(), lr=lr)\n",
    "# Instantiate scheduler\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0.06 * (len(train_dataset) * num_epochs),\n",
    "    num_training_steps=(len(train_dataset) * num_epochs),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "500a27b5-045a-4e49-8149-6b287c6b958a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 459/459 [03:10<00:00,  2.41it/s]\n",
      "  2%|▏         | 1/51 [00:00<00:14,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.328338), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-1.41292274e+00,  1.26946950e+00],\n",
      " [ 5.43053269e-01, -3.49333644e-01],\n",
      " [ 3.56838882e-01, -2.11381894e-02],\n",
      " ...\n",
      " [-2.51482487e+00,  2.02854371e+00],\n",
      " [ 2.07942817e-02,  2.60843813e-01],\n",
      " [-9.94655311e-01,  9.96531785e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/51 [00:00<00:13,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.118108), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-2.08759046e+00,  1.81351221e+00],\n",
      " [-6.60228610e-01,  7.28161573e-01],\n",
      " [-1.63275933e+00,  1.52737629e+00],\n",
      " ...\n",
      " [-9.53025579e-01,  1.01175523e+00],\n",
      " [-1.78741729e+00,  1.59429955e+00],\n",
      " [-1.02434838e+00,  1.11028755e+00]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/51 [00:00<00:09,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.365044), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-1.39409208e+00,  1.26762474e+00],\n",
      " [ 3.65849733e-01, -2.59407889e-02],\n",
      " [-2.67419505e+00,  2.12354445e+00],\n",
      " ...\n",
      " [ 9.61121917e-01, -4.34197396e-01],\n",
      " [ 6.54212713e-01, -2.40991369e-01],\n",
      " [-1.20784950e+00,  1.26777303e+00]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.332337), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-7.85808861e-01,  9.31611300e-01],\n",
      " [ 3.56511474e-01, -3.39316316e-02],\n",
      " [-9.60744098e-02,  1.61721379e-01],\n",
      " ...\n",
      " [-2.15801096e+00,  1.87628591e+00],\n",
      " [ 7.14399099e-01, -2.59613782e-01],\n",
      " [-2.54249930e+00,  2.03848910e+00]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/51 [00:01<00:06,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.417558), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-1.02254963e+00,  1.03731465e+00],\n",
      " [ 6.19135618e-01, -1.62092432e-01],\n",
      " [-1.92230511e+00,  1.67900789e+00],\n",
      " ...\n",
      " [ 3.92511249e-01,  6.64982721e-02],\n",
      " [-2.16319978e-01,  4.40935314e-01],\n",
      " [-2.37718344e+00,  1.88309813e+00]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.161879), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[ 1.14963603e+00, -6.05812013e-01],\n",
      " [-2.01874948e+00,  1.70900917e+00],\n",
      " [ 9.40621018e-01, -4.42785829e-01],\n",
      " ...\n",
      " [-1.89511895e+00,  1.61280346e+00],\n",
      " [-1.92788684e+00,  1.75394678e+00],\n",
      " [ 2.62000531e-01,  2.10053734e-02]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 7/51 [00:01<00:05,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.0538454), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-2.32429862e+00,  1.90337908e+00],\n",
      " [-1.26371300e+00,  1.16528440e+00],\n",
      " [-1.91586769e+00,  1.52557802e+00],\n",
      " ...\n",
      " [-1.52839935e+00,  1.21234334e+00],\n",
      " [-1.39522922e+00,  1.26250303e+00],\n",
      " [-1.44114339e+00,  1.37993407e+00]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.415291), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[ 8.53326738e-01, -3.91776681e-01],\n",
      " [-2.80504608e+00,  2.19153357e+00],\n",
      " [-7.52322197e-01,  7.99770176e-01],\n",
      " ...\n",
      " [ 3.48255992e-01,  1.06444709e-01],\n",
      " [-1.93671691e+00,  1.55842531e+00],\n",
      " [-1.26501930e+00,  1.13879347e+00]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 10/51 [00:01<00:04,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.227824), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.74467248e-01,  6.57728136e-01],\n",
      " [ 8.28260362e-01, -3.57374132e-01],\n",
      " [-2.36313033e+00,  1.90021110e+00],\n",
      " ...\n",
      " [-2.32793021e+00,  1.91445279e+00],\n",
      " [-1.35689664e+00,  1.22637582e+00],\n",
      " [-3.58080804e-01,  4.78656888e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.44422), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-3.94730866e-01,  6.13656044e-01],\n",
      " [-9.53336835e-01,  9.71205771e-01],\n",
      " [-1.26315928e+00,  1.21800995e+00],\n",
      " ...\n",
      " [-1.79701710e+00,  1.54348671e+00],\n",
      " [-2.06478858e+00,  1.72966588e+00],\n",
      " [-2.07201219e+00,  1.56591177e+00]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 12/51 [00:01<00:04,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.60076), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-1.41705441e+00,  1.23886371e+00],\n",
      " [-3.45930874e-01,  5.48328340e-01],\n",
      " [-1.14741063e+00,  1.14318633e+00],\n",
      " ...\n",
      " [-3.16325039e-01,  2.50677377e-01],\n",
      " [-1.12385726e+00,  1.08451390e+00],\n",
      " [ 1.07181966e+00, -5.36404371e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.275758), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-1.83450198e+00,  1.61554587e+00],\n",
      " [-2.61635208e+00,  2.11994457e+00],\n",
      " [ 1.20447949e-02,  3.39642674e-01],\n",
      " ...\n",
      " [-2.40722269e-01,  5.50779402e-01],\n",
      " [-1.75781548e+00,  1.55849802e+00],\n",
      " [-1.96138144e+00,  1.67258584e+00]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 14/51 [00:01<00:04,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.312175), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[ 1.23638213e+00, -6.10021293e-01],\n",
      " [-1.11253572e+00,  1.09686089e+00],\n",
      " [-1.68295407e+00,  1.48714530e+00],\n",
      " ...\n",
      " [ 9.87949669e-01, -3.78558189e-01],\n",
      " [-1.88155222e+00,  1.54399037e+00],\n",
      " [-1.70183122e+00,  1.31176436e+00]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.434714), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-2.44053677e-01,  4.16212946e-01],\n",
      " [-1.43195224e+00,  1.28883541e+00],\n",
      " [-1.56769156e+00,  1.45844281e+00],\n",
      " ...\n",
      " [-2.87074685e-01,  4.49195743e-01],\n",
      " [-1.81381047e-01,  4.70335662e-01],\n",
      " [ 6.30327940e-01, -1.78019613e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 16/51 [00:02<00:03,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.248125), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-7.59177089e-01,  8.75835776e-01],\n",
      " [-2.63317919e+00,  2.21401858e+00],\n",
      " [ 6.97358668e-01, -2.61312693e-01],\n",
      " ...\n",
      " [-2.68844128e+00,  2.11577916e+00],\n",
      " [-2.56316662e+00,  2.01947641e+00],\n",
      " [-2.54746079e+00,  2.01017523e+00]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.185906), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-1.99188447e+00,  1.64766622e+00],\n",
      " [-3.28709990e-01,  5.46938658e-01],\n",
      " [ 1.15464556e+00, -6.55819774e-01],\n",
      " ...\n",
      " [-2.04423475e+00,  1.68885601e+00],\n",
      " [-2.69635773e+00,  2.21778226e+00],\n",
      " [ 8.26928854e-01, -3.53896558e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 18/51 [00:02<00:03,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.385427), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-3.09650612e+00,  2.41565037e+00],\n",
      " [-1.91981983e+00,  1.60295510e+00],\n",
      " [-2.05094433e+00,  1.71646106e+00],\n",
      " ...\n",
      " [ 1.23815966e+00, -7.07913578e-01],\n",
      " [-1.21089017e+00,  1.13113892e+00],\n",
      " [-2.10573602e+00,  1.71723115e+00]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.470235), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[ 5.70267856e-01, -1.79631129e-01],\n",
      " [ 8.58384311e-01, -3.68981808e-01],\n",
      " [-3.21904230e+00,  2.44681692e+00],\n",
      " ...\n",
      " [-3.13780040e-01,  2.68227458e-01],\n",
      " [ 1.18675292e+00, -6.50011003e-01],\n",
      " [-7.54769266e-01,  7.77805686e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 20/51 [00:02<00:03,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.316543), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[ 2.54924178e-01, -1.89604402e-01],\n",
      " [ 7.16262043e-01, -2.55712658e-01],\n",
      " [-1.90899885e+00,  1.50818813e+00],\n",
      " ...\n",
      " [-1.91869986e+00,  1.70866656e+00],\n",
      " [ 1.27312922e+00, -6.94310129e-01],\n",
      " [ 4.87709969e-01, -9.24583748e-02]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.287342), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-2.91481256e+00,  2.29979515e+00],\n",
      " [-2.81404996e+00,  2.28941560e+00],\n",
      " [-1.57534122e+00,  1.47806239e+00],\n",
      " ...\n",
      " [-3.18778306e-01,  5.79395831e-01],\n",
      " [-5.29759005e-03,  2.07322344e-01],\n",
      " [-2.51338696e+00,  2.10432220e+00]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 22/51 [00:02<00:03,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.203482), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-8.21457446e-01,  8.79443288e-01],\n",
      " [-1.52138329e+00,  1.28577936e+00],\n",
      " [-2.50847912e+00,  2.05217767e+00],\n",
      " ...\n",
      " [-1.75906265e+00,  1.35703087e+00],\n",
      " [-1.80272207e-01,  3.77996802e-01],\n",
      " [ 1.49960411e+00, -8.32329035e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.541735), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-1.55729294e+00,  1.46102262e+00],\n",
      " [ 3.33558828e-01,  6.54427484e-02],\n",
      " [-1.50979254e-02,  3.10136378e-01],\n",
      " ...\n",
      " [-1.09021556e+00,  8.98602188e-01],\n",
      " [ 8.32948312e-02,  2.06818566e-01],\n",
      " [-1.31208742e+00,  1.29521489e+00]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 24/51 [00:03<00:03,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.236723), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-1.84036863e+00,  1.54902589e+00],\n",
      " [ 8.02597940e-01, -3.52575302e-01],\n",
      " [-5.11081994e-01,  6.94374502e-01],\n",
      " ...\n",
      " [ 2.63301879e-01,  8.87847990e-02],\n",
      " [-2.01752663e+00,  1.73217618e+00],\n",
      " [-1.50996959e+00,  1.39046896e+00]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.314534), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-4.43008661e-01,  6.00956440e-01],\n",
      " [-1.23515511e+00,  1.19160199e+00],\n",
      " [ 7.58449316e-01, -2.70199716e-01],\n",
      " ...\n",
      " [-1.89986062e+00,  1.63520420e+00],\n",
      " [-2.21657228e+00,  1.97114682e+00],\n",
      " [ 5.17968535e-01, -1.26339883e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 26/51 [00:03<00:02,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.358735), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-1.31012410e-01,  1.69831529e-01],\n",
      " [-1.38152981e+00,  1.29383552e+00],\n",
      " [-5.44749618e-01,  4.56579953e-01],\n",
      " ...\n",
      " [ 4.61213619e-01, -5.22117913e-02],\n",
      " [-2.67544538e-01,  4.21923876e-01],\n",
      " [-2.15749502e+00,  1.75595975e+00]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.425514), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-2.36545920e+00,  1.92747915e+00],\n",
      " [-5.21384060e-01,  7.38293409e-01],\n",
      " [ 8.46517861e-01, -3.70415956e-01],\n",
      " ...\n",
      " [ 9.86028254e-01, -3.66936713e-01],\n",
      " [-1.78399587e+00,  1.50323761e+00],\n",
      " [-2.41065907e+00,  1.98932862e+00]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 28/51 [00:03<00:02,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.262532), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-1.85776687e+00,  1.64799964e+00],\n",
      " [ 3.42731476e-01, -2.53272265e-01],\n",
      " [ 5.75120926e-01, -3.84095252e-01],\n",
      " ...\n",
      " [-1.90045521e-01,  3.92831355e-01],\n",
      " [-1.67706478e+00,  1.31421924e+00],\n",
      " [-2.86365199e+00,  2.22962666e+00]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.102043), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-9.72380459e-01,  9.80010808e-01],\n",
      " [-1.67339611e+00,  1.35822582e+00],\n",
      " [ 1.42131925e+00, -8.38337839e-01],\n",
      " ...\n",
      " [-1.04887903e+00,  1.11346924e+00],\n",
      " [-2.51872396e+00,  2.04738736e+00],\n",
      " [ 1.41539705e+00, -8.08526278e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 30/51 [00:03<00:02,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.0482121), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-2.03089929e+00,  1.75427139e+00],\n",
      " [-2.26471877e+00,  1.89660776e+00],\n",
      " [-2.89900517e+00,  2.31036758e+00],\n",
      " ...\n",
      " [-1.89088309e+00,  1.60296905e+00],\n",
      " [-2.07309794e+00,  1.73674297e+00],\n",
      " [-4.90046889e-01,  7.21762598e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.700346), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-1.31522810e+00,  1.23471761e+00],\n",
      " [-4.07074988e-01,  5.49332500e-01],\n",
      " [ 1.52864352e-01,  2.04475686e-01],\n",
      " ...\n",
      " [ 4.10677910e-01, -1.03719775e-02],\n",
      " [ 4.31571454e-01, -1.54038155e-02],\n",
      " [ 8.59857500e-01, -3.20846200e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 32/51 [00:03<00:02,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.335656), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-5.04652619e-01,  6.79192841e-01],\n",
      " [ 6.47982895e-01, -4.88577068e-01],\n",
      " [-1.71019316e+00,  1.49513614e+00],\n",
      " ...\n",
      " [-2.39644718e+00,  1.97384715e+00],\n",
      " [-2.40519023e+00,  2.00470853e+00],\n",
      " [-6.85939968e-01,  7.59051919e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.436935), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-1.45968068e+00,  1.33221018e+00],\n",
      " [-2.04867887e+00,  1.70713806e+00],\n",
      " [-1.22995079e+00,  1.19696236e+00],\n",
      " ...\n",
      " [ 7.46405542e-01, -3.53334635e-01],\n",
      " [ 9.21276450e-01, -4.04564381e-01],\n",
      " [ 1.39277267e+00, -8.38451445e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 34/51 [00:04<00:01,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.205694), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-1.98202729e+00,  1.68122113e+00],\n",
      " [-1.90825117e+00,  1.58338225e+00],\n",
      " [-7.09776103e-01,  7.88053155e-01],\n",
      " ...\n",
      " [ 2.88628995e-01, -2.43702233e-02],\n",
      " [-1.95461154e+00,  1.56880271e+00],\n",
      " [-1.18645430e+00,  1.20414495e+00]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.263753), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-5.72316460e-02,  2.72056967e-01],\n",
      " [-5.68277419e-01,  6.92334116e-01],\n",
      " [-1.52841425e+00,  1.35100710e+00],\n",
      " ...\n",
      " [-1.57187080e+00,  1.42087448e+00],\n",
      " [ 5.91828883e-01, -1.17840186e-01],\n",
      " [-1.91545081e+00,  1.66571712e+00]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 36/51 [00:04<00:01,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.152568), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-1.97155392e+00,  1.77162111e+00],\n",
      " [-2.26714587e+00,  1.89765608e+00],\n",
      " [-2.45918322e+00,  2.10206771e+00],\n",
      " ...\n",
      " [ 3.56340349e-01, -1.44797349e-02],\n",
      " [-2.64172339e+00,  2.14741373e+00],\n",
      " [ 1.06075144e+00, -4.29443747e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.575211), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-1.84731197e+00,  1.56940877e+00],\n",
      " [ 3.10422897e-01,  3.31388265e-02],\n",
      " [-2.10472748e-01,  3.30841392e-01],\n",
      " ...\n",
      " [-4.45291430e-01,  6.17001355e-01],\n",
      " [-1.20500827e+00,  1.17839873e+00],\n",
      " [ 1.05450785e+00, -4.63979870e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 38/51 [00:04<00:01,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.238983), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-1.76245308e+00,  1.55830479e+00],\n",
      " [ 2.51597404e-01,  6.56786487e-02],\n",
      " [-2.99436063e-01,  5.88667572e-01],\n",
      " ...\n",
      " [-5.28465271e-01,  6.74997628e-01],\n",
      " [-1.12231946e+00,  1.13496006e+00],\n",
      " [ 1.65776765e+00, -9.76423204e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.601857), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[ 7.91917801e-01, -3.21449131e-01],\n",
      " [-1.71614718e+00,  1.52537084e+00],\n",
      " [-1.73504448e+00,  1.55533659e+00],\n",
      " ...\n",
      " [-1.63624048e+00,  1.44781542e+00],\n",
      " [-1.57132387e+00,  1.49477041e+00],\n",
      " [ 3.95001441e-01, -2.30385199e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 40/51 [00:04<00:01,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.576515), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-1.10335290e+00,  1.11301756e+00],\n",
      " [-1.49804735e+00,  1.30641925e+00],\n",
      " [ 3.33784610e-01,  4.50178143e-03],\n",
      " ...\n",
      " [-4.29798186e-01,  6.36534870e-01],\n",
      " [-1.06073809e+00,  9.82450008e-01],\n",
      " [-3.10620546e+00,  2.41347575e+00]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.674079), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[ 1.41740039e-01,  1.32711187e-01],\n",
      " [ 9.05053377e-01, -4.07307774e-01],\n",
      " [-2.52310514e+00,  2.12341619e+00],\n",
      " ...\n",
      " [-1.70925570e+00,  1.48286116e+00],\n",
      " [-2.93913662e-01,  5.36278725e-01],\n",
      " [-5.25720596e-01,  6.40915990e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 42/51 [00:05<00:01,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.311125), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[ 3.62309009e-01,  6.15416877e-02],\n",
      " [ 1.07482576e+00, -5.39421737e-01],\n",
      " [ 1.59689820e+00, -9.18087065e-01],\n",
      " ...\n",
      " [-2.23139954e+00,  1.89177179e+00],\n",
      " [-5.40774107e-01,  6.98800921e-01],\n",
      " [-2.72307205e+00,  2.24025393e+00]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.170138), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-2.03060913e+00,  1.71126640e+00],\n",
      " [-1.79818332e-01,  4.39401537e-01],\n",
      " [-1.73519838e+00,  1.56011343e+00],\n",
      " ...\n",
      " [-6.48250401e-01,  7.88074553e-01],\n",
      " [-1.85711539e+00,  1.69151449e+00],\n",
      " [-7.86626101e-01,  8.84541631e-01]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 44/51 [00:05<00:00,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.407276), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-2.03547573e+00,  1.69282126e+00],\n",
      " [ 4.48899806e-01,  6.14027772e-03],\n",
      " [-8.62179995e-02,  3.19561213e-01],\n",
      " ...\n",
      " [-1.57703018e+00,  1.37640715e+00],\n",
      " [ 1.04930985e+00, -5.38510621e-01],\n",
      " [-1.33966357e-01,  4.46206927e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.16358), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-2.67720771e+00,  2.14181066e+00],\n",
      " [-2.07234907e+00,  1.76438701e+00],\n",
      " [-1.76695955e+00,  1.31884849e+00],\n",
      " ...\n",
      " [-8.43816578e-01,  9.70886409e-01],\n",
      " [ 6.45462692e-01, -3.05334955e-01],\n",
      " [-2.51243019e+00,  2.01461983e+00]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 46/51 [00:05<00:00,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.334635), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[ 2.14689046e-01,  1.01739474e-01],\n",
      " [-1.74029195e+00,  1.59533715e+00],\n",
      " [-5.20281971e-01,  6.55226529e-01],\n",
      " ...\n",
      " [-5.03928185e-01,  6.17154300e-01],\n",
      " [-1.57047153e+00,  1.44793606e+00],\n",
      " [-2.12623525e+00,  1.83676887e+00]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.369413), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[ 4.66436356e-01, -9.27328691e-02],\n",
      " [-2.18327212e+00,  1.84753931e+00],\n",
      " [-2.48066568e+00,  2.06529284e+00],\n",
      " ...\n",
      " [-2.11369061e+00,  1.85024726e+00],\n",
      " [-9.35541213e-01,  1.01126516e+00],\n",
      " [-1.41533470e+00,  1.32154167e+00]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 48/51 [00:05<00:00,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.375884), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[ 1.65785849e-01,  1.07963033e-01],\n",
      " [ 8.56327951e-01, -4.06905979e-01],\n",
      " [-2.58236217e+00,  2.01679730e+00],\n",
      " ...\n",
      " [-2.78312773e-01,  5.14823198e-01],\n",
      " [ 1.04389274e+00, -5.33609807e-01],\n",
      " [ 2.36884523e-02,  2.53416032e-01]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.548366), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-6.49581671e-01,  7.64875531e-01],\n",
      " [-3.54570925e-01,  6.10979855e-01],\n",
      " [ 7.73960799e-02,  2.96525329e-01],\n",
      " ...\n",
      " [-1.90306294e+00,  1.62861121e+00],\n",
      " [ 7.31134191e-02,  2.43254438e-01],\n",
      " [-2.09769845e+00,  1.75184667e+00]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 50/51 [00:05<00:00,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.323406), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[ 1.50972217e-01,  1.60172731e-01],\n",
      " [-2.57099748e-01,  4.23382193e-01],\n",
      " [-6.81506515e-01,  5.73573411e-01],\n",
      " ...\n",
      " [-9.08419371e-01,  7.42946684e-01],\n",
      " [-2.29774904e+00,  1.94723010e+00],\n",
      " [-1.05482042e+00,  1.08997667e+00]]), hidden_states=None, attentions=None)\n",
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.20652), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[-9.82591271e-01,  9.51394022e-01],\n",
      " [-2.30483556e+00,  1.95338595e+00],\n",
      " [-1.38186753e+00,  1.24483109e+00],\n",
      " ...\n",
      " [-1.67494029e-01,  4.17578757e-01],\n",
      " [-2.24125803e-01,  2.35049486e-01],\n",
      " [-1.90672302e+00,  1.69278133e+00]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:06<00:00,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:SequenceClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= 0.16791), logits=Tensor(shape=[8, 2], dtype=Float32, value=\n",
      "[[ 1.54139483e+00, -8.81597877e-01],\n",
      " [-2.06219029e+00,  1.68806553e+00],\n",
      " [-1.22359109e+00,  1.10582316e+00],\n",
      " ...\n",
      " [-2.33205843e+00,  1.92998803e+00],\n",
      " [ 9.18954790e-01, -4.24951047e-01],\n",
      " [-5.22007763e-01,  6.59988821e-01]]), hidden_states=None, attentions=None)\n",
      "epoch=2: train_ppl=Tensor(shape=[], dtype=Float32, value= 1.49413) train_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.401545) eval_ppl=Tensor(shape=[], dtype=Float32, value= 1.39602) eval_epoch_loss=Tensor(shape=[], dtype=Float32, value= 0.333623)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from mindnlp.core import value_and_grad\n",
    "# training and evaluation\n",
    "\n",
    "def forward_fn(**batch):\n",
    "    outputs = model(**batch)\n",
    "    loss = outputs.loss\n",
    "    return loss\n",
    "\n",
    "# 使用value_and_grad装饰前向传播函数，以便在训练时获取损失值和梯度\n",
    "grad_fn = value_and_grad(forward_fn, model.trainable_params())\n",
    "\n",
    "# 开始训练和评估循环\n",
    "for epoch in range(num_epochs):\n",
    "    # 设置模型为训练模式\n",
    "    model.set_train()\n",
    "    total_loss = 0\n",
    "    train_total_size = train_dataset.get_dataset_size()\n",
    "    # 遍历训练数据集\n",
    "    for step, batch in enumerate(tqdm(train_dataset.create_dict_iterator(), total=train_total_size)):\n",
    "        # 清除上一步的梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 计算损失值和梯度\n",
    "        loss = grad_fn(**batch)\n",
    "         # 更新模型参数\n",
    "        optimizer.step()\n",
    "        # 累加损失值\n",
    "        total_loss += loss.float() #这一步不一样\n",
    "        # 更新学习率调度器\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    # 设置模型为评估模式\n",
    "    model.set_train(False)\n",
    "    eval_loss = 0 #这一步没有\n",
    "    eval_preds = [] #这一步没有\n",
    "    eval_total_size = eval_dataset.get_dataset_size()\n",
    "    # 遍历评估数据集\n",
    "    for step, batch in enumerate(tqdm(eval_dataset.create_dict_iterator(), total=eval_total_size)):\n",
    "        # 禁用梯度计算，进行前向传播\n",
    "        # with mindspore._no_grad(): # 没有这句\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss        # 以下都不一样\n",
    "        eval_loss += loss.float()\n",
    "        # 对于序列分类任务，直接获取类别索引\n",
    "        print(f'outputs:{outputs}')\n",
    "        eval_preds.extend(ops.argmax(outputs.logits, -1).asnumpy().tolist())\n",
    "    \n",
    "# 计算评估期损失\n",
    "    eval_epoch_loss = eval_loss / len(eval_dataset)\n",
    "    eval_ppl = ops.exp(eval_epoch_loss)\n",
    "# 计算训练期损失\n",
    "    train_epoch_loss = total_loss / len(train_dataset)\n",
    "    train_ppl = ops.exp(train_epoch_loss)\n",
    "# 打印训练和评估结果\n",
    "    print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=} {eval_ppl=} {eval_epoch_loss=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b95a29e-3b1c-493e-916d-cb7bd5c1f44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_preds=[1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(f\"{eval_preds=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a913d1b6-f30d-496d-a970-ea097ecd210c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample logits: [[ 1.5413948  -0.8815979 ]\n",
      " [-2.0621903   1.6880655 ]\n",
      " [-1.2235911   1.1058232 ]\n",
      " [ 1.2690016  -0.6442656 ]\n",
      " [-0.11086565  0.34418398]\n",
      " [-2.3320584   1.929988  ]\n",
      " [ 0.9189548  -0.42495105]\n",
      " [-0.52200776  0.6599888 ]]\n"
     ]
    }
   ],
   "source": [
    "# 打印前5个样本的logits\n",
    "print(f\"Sample logits: {outputs.logits[:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b6c252c-f6d1-41f0-935b-e7b2aed0863f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:342,total:408\n",
      "accuracy=83.82352941176471 % on the evaluation dataset\n",
      "eval_preds[:10]=[1, 0, 0, 1, 0, 1, 1, 1, 1, 1]\n",
      "ground_truth[:10]=[1, 0, 0, 1, 0, 1, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# print accuracy\n",
    "# 初始化正确预测和总样本的计数器\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# 初始化用于存储真实标签的列表\n",
    "ground_truth = []\n",
    "\n",
    "# 遍历预测结果和验证数据集\n",
    "for pred, data in zip(eval_preds, datasets['validation'].create_dict_iterator(output_numpy=True)):\n",
    "    # 获取真实的文本标签\n",
    "    true = int(data['label'])\n",
    "    # 将真实标签添加到ground_truth列表中\n",
    "    ground_truth.append(true)\n",
    "    # 如果预测的标签与真实标签一致，则正确计数器加一\n",
    "    if pred == true:\n",
    "        correct += 1\n",
    "    # 总样本计数器加一\n",
    "    total += 1\n",
    "print(f'correct:{correct},total:{total}')\n",
    "# 计算准确率\n",
    "accuracy = correct / total * 100\n",
    "# 输出准确率\n",
    "print(f\"{accuracy=} % on the evaluation dataset\")\n",
    "# 输出前10个预测结果\n",
    "print(f\"{eval_preds[:10]=}\")\n",
    "# 输出前10个真实标签\n",
    "print(f\"{ground_truth[:10]=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77adfbb0-f8fc-43e0-aad2-42d7f604cbf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <mindspore.dataset.engine.datasets_user_defined.GeneratorDataset at 0xfffe3e6af940>,\n",
       " 'validation': <mindspore.dataset.engine.datasets_user_defined.GeneratorDataset at 0xfffde9d18580>,\n",
       " 'test': <mindspore.dataset.engine.datasets_user_defined.GeneratorDataset at 0xfffde9d18460>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26e88eb1-3d24-488b-ad62-0c18b81b861e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tensor(shape=[8, 73], dtype=Int64, value=\n",
       " [[    0,   894,    26 ...     1,     1,     1],\n",
       "  [    0, 43600,  1322 ...     1,     1,     1],\n",
       "  [    0,   133,  1404 ...   135,   479,     2],\n",
       "  ...\n",
       "  [    0, 30888,    12 ...     1,     1,     1],\n",
       "  [    0,  5771,   385 ...     1,     1,     1],\n",
       "  [    0,   713, 33752 ...     1,     1,     1]]),\n",
       " Tensor(shape=[8, 73], dtype=Int64, value=\n",
       " [[1, 1, 1 ... 0, 0, 0],\n",
       "  [1, 1, 1 ... 0, 0, 0],\n",
       "  [1, 1, 1 ... 1, 1, 1],\n",
       "  ...\n",
       "  [1, 1, 1 ... 0, 0, 0],\n",
       "  [1, 1, 1 ... 0, 0, 0],\n",
       "  [1, 1, 1 ... 0, 0, 0]]),\n",
       " Tensor(shape=[8], dtype=Int64, value= [1, 0, 0, 1, 0, 1, 0, 1])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取数据集迭代器的下一个元素\n",
    "next(eval_dataset.create_tuple_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8de6005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "# 构建PEFT模型的唯一标识符\n",
    "# 该标识符结合了模型名称或路径、PEFT配置的类型和任务类型，用于区分不同的PEFT模型\n",
    "peft_model_id = f\"{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}\"\n",
    "\n",
    "# 保存预训练的PEFT模型\n",
    "# 使用构建的PEFT模型标识符作为模型ID，将模型保存到指定目录或路径\n",
    "model.save_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd20cd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.7M\troberta-large_IA3_SEQ_CLS/adapter_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# 构建checkpoint文件的路径\n",
    "ckpt = f\"{peft_model_id}/adapter_model.ckpt\"\n",
    "# 使用shell命令检查checkpoint文件的大小\n",
    "!du -h $ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76c2fc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 导入Peft模型和配置相关的模块\n",
    "from mindnlp.peft import PeftModel, PeftConfig\n",
    "\n",
    "# 构造Peft模型的唯一标识符\n",
    "# 这里使用模型名称或路径、Peft配置的类型和任务类型来组合成一个字符串\n",
    "peft_model_id = f\"{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}\"\n",
    "\n",
    "# 从预训练的Peft模型中加载配置\n",
    "# 这里的配置将指导如何加载和使用Peft模型\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "# 从配置中加载基础模型\n",
    "# 这个基础模型是用于执行序列到序列语言模型任务的\n",
    "model = AutoModelForSequenceClassification.from_pretrained(config.base_model_name_or_path)\n",
    "# 使用Peft模型对基础模型进行微调\n",
    "# 这一步是将基础模型与Peft模型的特定微调参数结合起来\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37d712ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examle:{'input_ids': array([[    0,   894,    26,     5,   689, 11131, 11637,   265,   630,\n",
      "          128,    90,  2564,     5,   138,   128,    29,   251,    12,\n",
      "         1279,   434,  1860,   479,     2,     2,   113,    20,   689,\n",
      "        11131, 11637,   265,   473,    45,  2564,    84,   251,    12,\n",
      "         1279,   434,  1860,   479,     2,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1],\n",
      "       [    0, 43600,  1322, 10054,    26, 14822,   636,  1242, 19975,\n",
      "            5,  7780,  4304,     8,  1415,   556,     7,   634,    39,\n",
      "          251,   107,     9,  1058,    11,     5,   997,   479,     2,\n",
      "            2,  9962,  1141,    26,    37,    21,    22,   727,   135,\n",
      "          639,  1655,  3516,    22,     8,  1415,   556,     7,   634,\n",
      "           39,   107,     9,  1058,    11,     5,   997,   479,     2,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1],\n",
      "       [    0,   133,  1404,    21,    23, 15966,     4,  6617,  4796,\n",
      "          136,     5,  4796,  2156,  3269,    15,     5,  1852,  2156,\n",
      "            8,    23,   112,     4,  2517,  6468,   136,     5,  5092,\n",
      "        13638,  2156,    67,  3269,   479,     2,     2,   133,  1404,\n",
      "           21,    23, 15966,     4,  5479,  4796, 14621,   975,  5457,\n",
      "         2156,  8077,  3269,    15,     5,  1852,  2156,     8,    23,\n",
      "          112,     4,  2517,  5339,   136,     5,  5092, 13638,  3858,\n",
      "          597,  5457,  2156,   159,   321,     4,   134,   135,   479,\n",
      "            2],\n",
      "       [    0,   133, 16305,    12,   347,  6454,    16,  2445,   454,\n",
      "          779,     7,  2845,   114,    24,    40, 18839,    10,  1984,\n",
      "          479,     2,     2,   133, 16305,    12,   347,  6454,   585,\n",
      "          307,    14,    24,    40,  2845,    11,   779,   549,     7,\n",
      "        18839,    10,  1984,   137,     5, 19050,   479,     2,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1],\n",
      "       [    0,  3084,  5461,    33,    57,   278,    13,     5,  2366,\n",
      "           50,     5,  1837,  1500,   479,     2,     2,  3084,  5461,\n",
      "           33,    57,   278,    13,     5,  1837,    50,  2366,  1200,\n",
      "         2156,    53, 18966,   607,    34,  4407,    45,  2181,   479,\n",
      "            2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1],\n",
      "       [    0, 30888,    12, 13012,    26,    24,    74,  1649,    70,\n",
      "            9,    63,   153,    12,  7269,  1897,  1138,     7,  1306,\n",
      "           51,    58,  7818,  7460,   479,     2,     2,   243,    34,\n",
      "           67,    26,    24,    74,  1551,    70,     9,    63,  1897,\n",
      "         1321,    55,    87,   112,   153,     7,  1306,    51,    33,\n",
      "         1030,  2194,   479,     2,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1],\n",
      "       [    0,  5771,   385, 44882,   179,  1389,    11,     5,  1737,\n",
      "           58,    62,    94,    76,  2156,    51,    33,  1882,    30,\n",
      "         3337,   135,   187,     5,  6200,    29,  2156,    26,  7233,\n",
      "         3056,   479,     2,     2,   133,  2534,    26,   385, 44882,\n",
      "          179,  1389,    11,     5,  1737,    33,  4491,    30,    25,\n",
      "          203,    25,  5553,   135,   187,     5,  6200,    29,   479,\n",
      "            2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1],\n",
      "       [    0,   713, 33752,    19, 42083, 11834,  4591, 27576,     8,\n",
      "         2386,  5485,     7,   173,    11,  2800,  7952,     9, 24549,\n",
      "         2156, 25878,   230,   849,     8, 25878, 17255,   479, 13548,\n",
      "            4,     2,     2,  8863,   448,    26,     5, 42083,   785,\n",
      "           58,    67,  6818,    19, 42083, 11834,  4591, 27576,  2156,\n",
      "           61,  2386,  5485,     7,   173,    11, 24549,  2156, 25878,\n",
      "          230,   849,     8, 25878, 46255,   479, 15721,     4,     2,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1]], dtype=int64), 'attention_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0]], dtype=int64), 'labels': array([1, 0, 0, 1, 0, 1, 0, 1], dtype=int64)}\n",
      "[1 0 0 1 0 1 0 1]\n",
      "Inputs:{'input_ids': Tensor(shape=[1, 12], dtype=Int64, value=\n",
      "[[    0, 10975,   134 ...   112,   742,     2]]), 'attention_mask': Tensor(shape=[1, 12], dtype=Int64, value=\n",
      "[[1, 1, 1 ... 1, 1, 1]])}\n",
      "Outputs:[0 1 1 0 1 1 0 1]\n",
      "Sample 1: Dissimilar\n",
      "Sample 2: Similar\n",
      "Sample 3: Similar\n",
      "Sample 4: Dissimilar\n",
      "Sample 5: Similar\n",
      "Sample 6: Similar\n",
      "Sample 7: Dissimilar\n",
      "Sample 8: Similar\n"
     ]
    }
   ],
   "source": [
    "# 设置模型为评估模式，以禁用dropout等训练时的行为\n",
    "model.set_train(False)\n",
    "# 从验证数据集中获取一个样本，以便后续进行推理演示\n",
    "example = next(eval_dataset.create_dict_iterator(output_numpy=True))\n",
    "\n",
    "# 打印样本'input_ids'、'attention_mask'和'labels'\n",
    "print(f\"Examle:{example}\")\n",
    "# 打印样本中的文本标签，以便用户了解正在处理的数据\n",
    "print(example['labels'])\n",
    "# 使用tokenizer对样本文本进行编码，以将其转换为模型可处理的输入格式\n",
    "inputs = tokenizer(example['labels'], return_tensors=\"ms\")\n",
    "# 打印编码后的输入，以展示输入格式和内容\n",
    "print(f\"Inputs:{inputs}\")\n",
    "\n",
    "# 禁用梯度计算，以减少计算资源消耗，因为推理过程不需要反向传播\n",
    "with mindspore._no_grad():\n",
    "    # 使用模型生成分类结果\n",
    "    outputs = model(**batch)\n",
    "    outputs = outputs.logits.argmax(axis=-1)\n",
    "    # 打印生成的分类结果\n",
    "    print(f\"Outputs:{outputs}\")\n",
    "    \n",
    "    # 根据MRPC数据集的定义，0代表不相似，1代表相似。将生成的分类结果转换回人类可读的文本格式，并打印\n",
    "    label_names = ['Dissimilar', 'Similar']\n",
    "    \n",
    "    # 获取每个样本的最大概率对应的类别索引\n",
    "    predicted_class_indices = outputs.asnumpy()\n",
    "    \n",
    "    # 将类别索引转换为人类可读的标签\n",
    "    predicted_labels = [label_names[index] for index in predicted_class_indices]\n",
    "    \n",
    "    # 打印分类结果\n",
    "    for i, label in enumerate(predicted_labels):\n",
    "        print(f\"Sample {i+1}: {label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
