{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18a8de8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 基础思路（baseline）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa932cfc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 步骤1：更新或安装所需环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5a53f23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T11:28:02.452504Z",
     "iopub.status.busy": "2025-01-12T11:28:02.452331Z",
     "iopub.status.idle": "2025-01-12T11:28:15.451846Z",
     "shell.execute_reply": "2025-01-12T11:28:15.451259Z",
     "shell.execute_reply.started": "2025-01-12T11:28:02.452479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Requirement already satisfied: modelscope in /usr/local/lib/python3.10/site-packages (1.22.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (2.32.3)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests) (2024.12.14)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n",
      "\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade modelscope requests urllib3 tqdm pandas\n",
    "!apt update > /dev/null; apt install aria2 git-lfs axel -y > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683b4361",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 步骤2：下载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e631c84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T11:28:15.452829Z",
     "iopub.status.busy": "2025-01-12T11:28:15.452559Z",
     "iopub.status.idle": "2025-01-12T11:28:15.721521Z",
     "shell.execute_reply": "2025-01-12T11:28:15.721018Z",
     "shell.execute_reply.started": "2025-01-12T11:28:15.452807Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing download: https://ai-contest-static.xfyun.cn/2024/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B%E8%AF%84%E6%B5%8B%EF%BC%9A%E4%B8%AD%E6%96%87%E6%88%90%E8%AF%AD%E9%87%8A%E4%B9%89%E4%B8%8E%E8%A7%A3%E6%9E%90%E6%8C%91%E6%88%98%E8%B5%9B/test_input.csv\n",
      "ERROR 403: Forbidden.\n"
     ]
    }
   ],
   "source": [
    "!axel -n 12 -a https://ai-contest-static.xfyun.cn/2024/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B%E8%AF%84%E6%B5%8B%EF%BC%9A%E4%B8%AD%E6%96%87%E6%88%90%E8%AF%AD%E9%87%8A%E4%B9%89%E4%B8%8E%E8%A7%A3%E6%9E%90%E6%8C%91%E6%88%98%E8%B5%9B/test_input.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13b85fa",
   "metadata": {},
   "source": [
    "## 步骤3：构建模型（使用Qwen2-7B-Instruct）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c0e04dd",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-01-12T11:28:15.722824Z",
     "iopub.status.busy": "2025-01-12T11:28:15.722633Z",
     "iopub.status.idle": "2025-01-12T11:32:11.289601Z",
     "shell.execute_reply": "2025-01-12T11:32:11.289061Z",
     "shell.execute_reply.started": "2025-01-12T11:28:15.722803Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: /mnt/workspace/.cache/modelscope/qwen/Qwen2-7B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.24it/s]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: /mnt/workspace/.cache/modelscope/qwen/Qwen2-7B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "from modelscope import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"qwen/Qwen2-7B-Instruct\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"qwen/Qwen2-7B-Instruct\")\n",
    "\n",
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    model_inputs.input_ids,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aeb786",
   "metadata": {},
   "source": [
    "## 步骤4：读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "579d0f7f-a511-4d53-9b6c-a4cd1fcc2b87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T11:32:11.290600Z",
     "iopub.status.busy": "2025-01-12T11:32:11.290212Z",
     "iopub.status.idle": "2025-01-12T11:32:11.296900Z",
     "shell.execute_reply": "2025-01-12T11:32:11.296433Z",
     "shell.execute_reply.started": "2025-01-12T11:32:11.290579Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv('./test_input.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f67aed74-9059-48a0-b0b8-3750f8ec22fe",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-01-12T11:32:11.297737Z",
     "iopub.status.busy": "2025-01-12T11:32:11.297431Z",
     "iopub.status.idle": "2025-01-12T11:32:11.301290Z",
     "shell.execute_reply": "2025-01-12T11:32:11.300817Z",
     "shell.execute_reply.started": "2025-01-12T11:32:11.297718Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集的大小为: 2972\n",
      "前50条数据如下：\n",
      "\n",
      "双方心往一处想，意志坚定。\n",
      "两端都极为艰难，难以作出决定。\n",
      "雄浑深远的意旨。细腻微妙。高超巧妙。\n",
      "描述水流湍急，且快速且深远。\n",
      "避免被引诱做出不道德或可疑的行为。\n",
      "肘部肩窝。比喻事物发生于身边。\n",
      "他张开嘴巴，吞咽着口水。\n",
      "仅见一面，不足以深入了解。\n",
      "向四处散发施舍，同时手中拿着碗盆。\n",
      "比喻把装备脱下，放下武器。\n",
      "对于任何战役，都要一败涂地。\n",
      "阴谋真相已经昭然于众。\n",
      "比喻因为无能为力而写下了好文章。\n",
      "古代文人士大夫经常举行诗歌朗诵会。\n",
      "不能形容为不高兴，只能说明没劲儿。\n",
      "表现得举止端庄，很有教养。\n",
      "1.洗刷兵器2.喂养战马3.准备作战\n",
      "关注生命垂危者，关怀濒危者。\n",
      "比喻面对挑战，坚韧不拔地前行。\n",
      "过去的科举考试中被选拔为进士的称号。\n",
      "相似程度极高或相差无几。\n",
      "比喻不断地补充、堆砌和延伸。\n",
      "以安逸快乐的生活和劳动为重。\n",
      "她仍然每天教导她的儿子。\n",
      "犹以火为耕，比喻原始、简朴的农耕方式。\n",
      "指困境中处于不利地位。\n",
      "搜集和研究其内在道理。\n",
      "没有任何人帮助和支持。\n",
      "这位作者的文章风格与自己非常相似。\n",
      "国力强大，军事力量已经停止。\n",
      "相互勾结维持；相互利用。\n",
      "比喻进程飞快，日行千里。\n",
      "只有一个目的，追求利润。\n",
      "务必谨慎对待，慎重处理事务。\n",
      "无法言表，只能感慨万千。\n",
      "形容气势磅礴的文章风格。\n",
      "根据贡献的大小给予奖励。\n",
      "让国家蒙羞，民众蒙难。\n",
      "形容有权势的人极其残忍和无礼。\n",
      "坚决要求再次向某人强调。\n",
      "采取措施；采取办法；采取行动；实行\n",
      "心中充满了疑惑，还没有找到解答。\n",
      "累累罪行，遍历无穷。形容罪恶极重。\n",
      "形容人的容貌清爽俊雅，风度翩翩。\n",
      "辞掉本职工作去做其他的事情。\n",
      "秦汉时期，勋位至高者都佩戴金印和紫绶。\n",
      "创立独特的风格，与众不同。\n",
      "到处都是冰雪覆盖的环境，形容严冬天气。\n",
      "旧事物被废弃；为了新事物而采取措施。\n",
      "①向人行礼。②用作哀悼词或祭奠语。\n"
     ]
    }
   ],
   "source": [
    "# 查看数据集大小\n",
    "print(f\"数据集的大小为: {test.shape[0]}\\n前50条数据如下：\\n\")\n",
    "\n",
    "# 查看前50条赛事数据集（赛题要求根据每行句子，给出5个可能匹配的成语）\n",
    "for test_prompt in test[0].values[:50]:\n",
    "    print(test_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5fbc56-26d4-4131-b8f9-452899ead64b",
   "metadata": {},
   "source": [
    "## 步骤5：输出成语"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06baea3-940e-4a14-885b-b8175075efdc",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-01-12T12:13:29.877521Z",
     "iopub.status.busy": "2025-01-12T12:13:29.877151Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度:   0%|          | 0/2972 [00:00<?, ?it/s]/usr/local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:650: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n",
      "处理进度:   0%|          | 5/2972 [01:46<17:29:05, 21.22s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "\n",
    "i = 1\n",
    "# 假设 test 是一个 DataFrame\n",
    "# 遍历测试数据集的第一项的值，目的是生成与给定句子最相关的五个成语\n",
    "for test_prompt in tqdm(test[0].values, total=len(test[0].values), desc=\"处理进度\"):\n",
    "    i = i + 1\n",
    "    # 构造提示信息，要求模型输出与句子最相关的五个成语\n",
    "    prompt = f\"把下面句子总结为五个成语，写在一行中：{test_prompt}\"\n",
    "\n",
    "    # 初始化一个长度为5的列表，填充默认成语“同舟共济”\n",
    "    words = ['同舟共济'] * 5\n",
    "\n",
    "    # 构建聊天消息格式，用于提示模型进行生成\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    # 应用聊天模板对消息进行处理，准备模型输入\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    # 对输入文本进行编码，准备模型输入数据\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # 生成回答，限制最大生成长度\n",
    "    generated_ids = model.generate(\n",
    "        model_inputs.input_ids,\n",
    "        num_beams=3,# 5 已经超显存了\n",
    "        no_repeat_ngram_size=2,\n",
    "        num_return_sequences=3,\n",
    "        do_sample=False,\n",
    "        length_penalty=1.0,\n",
    "        \n",
    "    )\n",
    "    # 提取模型输出，去除输入部分\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    # 解码模型输出，去除特殊标记\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    # 清理回答文本，确保格式统一\n",
    "    response = response.replace('\\n', ' ').replace('、', ' ')\n",
    "    # 提取回答中的成语，确保每个成语长度为4且非空\n",
    "    words =  response # [x for x in response.split() if len(x) == 4 and x.strip() != '']\n",
    "    \n",
    "    \n",
    "\n",
    "    # 如果生成的成语列表长度不满足要求（即20个字符），则使用默认成语列表\n",
    "    #if len(' '.join(words).strip()) != 24:\n",
    "        #words = ['同舟共济'] * 5\n",
    "\n",
    "    # 将最终的成语列表写入提交文件\n",
    "    with open('submit.csv', 'a+', encoding='utf-8') as up:\n",
    "        up.write(' '.join(words) + '\\n')\n",
    "\n",
    "    \n",
    "    # 查看阶段性结果\n",
    "    if i % 50 == 0:\n",
    "        tqdm.write(f\"大模型第{i}次返回的结果是：\\n   {response}\\n\")\n",
    "        tqdm.write(f\"submit.cvs第{i}行输出结果：\\n   {words}\\n\")\n",
    "    \n",
    "    # 为了尽快拿到结果，我们暂时仅获得500个结果（如果有时间的话，可以删除这两行）\n",
    "    if i == 10:\n",
    "        break\n",
    "\n",
    "print('submit.csv 已生成')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
